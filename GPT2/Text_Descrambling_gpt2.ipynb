{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmx4nWm/vxp0uZfSGRD27V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/damilojohn/Text-Descrambling/blob/main/GPT2/Text_Descrambling_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ1cbP2q2AMQ",
        "outputId": "96938bc4-7086-4416-f7f3-7f98be9f1921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        " !pip install -qU transformers datasets nvidia-ml-py3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n"
      ],
      "metadata": {
        "id": "liRIoHTGFi3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_path = '/content/drive/MyDrive/Colab datasets/Text-Deshuffling/train (8).csv'\n",
        "test_path = '/content/drive/MyDrive/Colab datasets/Text-Deshuffling/test (9).csv'\n",
        "val_path= '/content/drive/MyDrive/Colab datasets/Text-Deshuffling/val (1).csv'\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "val_df = pd.read_csv(val_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pCNpmvGFi1P",
        "outputId": "37b32376-ef3a-4be6-91f2-559811abc248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiWoIzkwHLnG",
        "outputId": "6be867a8-c3b4-49a3-8c13-468fcb9ccb5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  presented here Furthermore, naive improved. im...   \n",
              "1  vector a in a form vector multidimensional spa...   \n",
              "2  compatible of The model with recent is model s...   \n",
              "3  but relevance outlined. hemodynamics its based...   \n",
              "4  of transitions lever-like involve reorientatio...   \n",
              "\n",
              "                                               label  id  \n",
              "0  Furthermore, the naive implementation presente...   0  \n",
              "1  Those coefficients form a vector in a multidim...   1  \n",
              "2  The model is compatible with a recent model of...   2  \n",
              "3  The model is based on electrophysiology, but i...   3  \n",
              "4  Conformational transitions in macromolecular c...   4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8723e7e3-f3c5-4b26-8d77-194f7893d337\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>presented here Furthermore, naive improved. im...</td>\n",
              "      <td>Furthermore, the naive implementation presente...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vector a in a form vector multidimensional spa...</td>\n",
              "      <td>Those coefficients form a vector in a multidim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>compatible of The model with recent is model s...</td>\n",
              "      <td>The model is compatible with a recent model of...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>but relevance outlined. hemodynamics its based...</td>\n",
              "      <td>The model is based on electrophysiology, but i...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>of transitions lever-like involve reorientatio...</td>\n",
              "      <td>Conformational transitions in macromolecular c...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8723e7e3-f3c5-4b26-8d77-194f7893d337')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8723e7e3-f3c5-4b26-8d77-194f7893d337 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8723e7e3-f3c5-4b26-8d77-194f7893d337');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['length'] = train_df['text'].apply(lambda x : len(x.split(' ')))"
      ],
      "metadata": {
        "id": "utVHbAHSG9Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dE8cqltHR1U",
        "outputId": "c4f0768f-31ec-4b90-af4c-444e5610694b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  \\\n",
              "0      presented here Furthermore, naive improved. im...   \n",
              "1      vector a in a form vector multidimensional spa...   \n",
              "2      compatible of The model with recent is model s...   \n",
              "3      but relevance outlined. hemodynamics its based...   \n",
              "4      of transitions lever-like involve reorientatio...   \n",
              "...                                                  ...   \n",
              "39996  for pose a clutter. estimation autonomous mani...   \n",
              "39997  objects added warehouses bin-picking present s...   \n",
              "39998  validation The proposed real-world on is metho...   \n",
              "39999  a between modes. statistics survival qualitati...   \n",
              "40000  a image super of resolution great low-level vi...   \n",
              "\n",
              "                                                   label     id  length  \n",
              "0      Furthermore, the naive implementation presente...      0       9  \n",
              "1      Those coefficients form a vector in a multidim...      1      10  \n",
              "2      The model is compatible with a recent model of...      2      12  \n",
              "3      The model is based on electrophysiology, but i...      3      14  \n",
              "4      Conformational transitions in macromolecular c...      4      12  \n",
              "...                                                  ...    ...     ...  \n",
              "39996  Object pose estimation is a crucial prerequisi...  39996      15  \n",
              "39997  Real-world bin-picking settings such as wareho...  39997      15  \n",
              "39998  The proposed method is evaluated on a syntheti...  39998      14  \n",
              "39999  This breakdown is associated with a crossover ...  39999      15  \n",
              "40000  Single image super resolution is of great impo...  40000      14  \n",
              "\n",
              "[40001 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-104227dc-2477-42e2-980a-fd0d8acac560\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>presented here Furthermore, naive improved. im...</td>\n",
              "      <td>Furthermore, the naive implementation presente...</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vector a in a form vector multidimensional spa...</td>\n",
              "      <td>Those coefficients form a vector in a multidim...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>compatible of The model with recent is model s...</td>\n",
              "      <td>The model is compatible with a recent model of...</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>but relevance outlined. hemodynamics its based...</td>\n",
              "      <td>The model is based on electrophysiology, but i...</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>of transitions lever-like involve reorientatio...</td>\n",
              "      <td>Conformational transitions in macromolecular c...</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39996</th>\n",
              "      <td>for pose a clutter. estimation autonomous mani...</td>\n",
              "      <td>Object pose estimation is a crucial prerequisi...</td>\n",
              "      <td>39996</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39997</th>\n",
              "      <td>objects added warehouses bin-picking present s...</td>\n",
              "      <td>Real-world bin-picking settings such as wareho...</td>\n",
              "      <td>39997</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39998</th>\n",
              "      <td>validation The proposed real-world on is metho...</td>\n",
              "      <td>The proposed method is evaluated on a syntheti...</td>\n",
              "      <td>39998</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39999</th>\n",
              "      <td>a between modes. statistics survival qualitati...</td>\n",
              "      <td>This breakdown is associated with a crossover ...</td>\n",
              "      <td>39999</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40000</th>\n",
              "      <td>a image super of resolution great low-level vi...</td>\n",
              "      <td>Single image super resolution is of great impo...</td>\n",
              "      <td>40000</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40001 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-104227dc-2477-42e2-980a-fd0d8acac560')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-104227dc-2477-42e2-980a-fd0d8acac560 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-104227dc-2477-42e2-980a-fd0d8acac560');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(train_df['length'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEU1lZDkN7tz",
        "outputId": "73d731e0-a554-4bbb-fb25-05c8bde7ca28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "b60703e06ced4dd38fac5b429fb601d7",
            "4036691060c64b76acedf6666e34c369",
            "3e62534ea5964457b9101a0be486fa81"
          ]
        },
        "id": "v3LtHbATHi2N",
        "outputId": "af941f44-1d3d-4e1a-8301-e330607412c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b60703e06ced4dd38fac5b429fb601d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4036691060c64b76acedf6666e34c369"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e62534ea5964457b9101a0be486fa81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py6-SE4cInIW",
        "outputId": "2995f4e2-5b0e-41a1-bba9-2124b152ba65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|startoftext|> token has the id 50257\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|pad|> has the id 50258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2 #gpt2 is a very large model \n",
        "#creating a standard pytorch dataset \n",
        "class GPT2dataset(Dataset):\n",
        "  def __init__(self,df,tokenizer,gpt_type='gpt2',max_length=20):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "    self.label_ids = []\n",
        "\n",
        "    for input,label in zip(df['text'],df['label']):\n",
        "       inputs = tokenizer('<|startoftext|>'+ input + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "       labels = tokenizer('<|startoftext|>' + label + '<|endoftext|>',truncation=True,max_length=max_length,padding='max_length')\n",
        "       self.input_ids.append(torch.tensor(inputs['input_ids']))\n",
        "       self.attn_masks.append(torch.tensor(inputs['attention_mask']))\n",
        "       self.label_ids.append(torch.tensor(labels['input_ids']))\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx],self.attn_masks[idx],self.label_ids[idx]\n"
      ],
      "metadata": {
        "id": "wrep0i75JMGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = GPT2dataset(train_df,tokenizer,max_length=20)\n",
        "val_dataset = GPT2dataset(val_df,tokenizer,max_length=20)\n"
      ],
      "metadata": {
        "id": "i6SOdXRXPsGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dataloaders \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "VnOa1ceZPS_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = GPT2Config.from_pretrained('gpt2',output_hidden_states=False)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2',config=configuration)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "bb0f5fb10b444e9eaad9f668549d10ad",
            "69162b574ccd4f4786778383df4c018e"
          ]
        },
        "id": "TyGNOGBJgeBY",
        "outputId": "0b248e63-0a32-48b8-b6d0-cf6c95b8fce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb0f5fb10b444e9eaad9f668549d10ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69162b574ccd4f4786778383df4c018e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer\n",
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsr1FZiGhklR",
        "outputId": "4275b8d7-8f4c-4b9e-f464-d30ada60389c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "2PgZYiGNhsjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIWftaA8kE1T",
        "outputId": "6e5b0ae9-4610-4ae3-b05e-2b3a3344a1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[50257, 20358,   257,  4981,   734,  4693,    13,   319,  1022,  1848,\n",
              "          30135,   338, 15974,   262,  2312,  3965,  3292,    12,  2364,   329],\n",
              "         [50257, 32861,    13,   287,   284,   554,   356,   670,    11,  4886,\n",
              "          10618,   290,  1660,  4031,   428, 50256, 50258, 50258, 50258, 50258]]),\n",
              " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]]),\n",
              " tensor([[50257,  4711,  4981,  1848,   329,   257,  3292,    12,  2364,  1022,\n",
              "            262, 30135,   338,  1368,  3965,   319,   734, 15974,  4693,    13],\n",
              "         [50257,   818,   428,   670,    11,   356,  4031,   284, 10618,   290,\n",
              "           4886,  1660,   287,  5861,    13, 50256, 50258, 50258, 50258, 50258]])]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop \n",
        "total_train_loss = 0 \n",
        "model.train()\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "for epoch in range(epochs):\n",
        "  #forward pass \n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_attention_masks = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    model.zero_grad()\n",
        "    outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_attention_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "    loss = outputs[0]\n",
        "    batch_loss = loss.item()\n",
        "    total_train_loss += batch_loss\n",
        "    if step % sample_every == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.'.format(step, len(train_dataloader), batch_loss,))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oavlS8Ei9i3",
        "outputId": "b16ce9ba-108d-4ab0-c75a-ed945f011cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.00\n",
            "\n",
            "  Average training loss: 0.01\n",
            "\n",
            "  Average training loss: 0.01\n",
            "\n",
            "  Average training loss: 0.02\n",
            "\n",
            "  Average training loss: 0.02\n",
            "\n",
            "  Average training loss: 0.02\n",
            "\n",
            "  Average training loss: 0.03\n",
            "\n",
            "  Average training loss: 0.03\n",
            "\n",
            "  Average training loss: 0.03\n",
            "\n",
            "  Average training loss: 0.03\n",
            "\n",
            "  Average training loss: 0.03\n",
            "\n",
            "  Average training loss: 0.03\n",
            "\n",
            "  Average training loss: 0.03\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.04\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.05\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Batch   100  of  20,001. Loss: 6.484448432922363.\n",
            "0: This is-\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.07\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.08\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.09\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.10\n",
            "  Batch   200  of  20,001. Loss: 6.919572353363037.\n",
            "0: S. The the The The the of\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.10\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.11\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Batch   300  of  20,001. Loss: 4.457761287689209.\n",
            "0: The approach the approach the approach the approach approach approach for approach approach\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.12\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.13\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.14\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.15\n",
            "  Batch   400  of  20,001. Loss: 6.902859210968018.\n",
            "0: We present approach, for of this for. this approach.. the.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.15\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.16\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.17\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.18\n",
            "  Batch   500  of  20,001. Loss: 6.620515823364258.\n",
            "0: We are a a system a in approach architecture approach approach- in method\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.18\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.19\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.20\n",
            "  Batch   600  of  20,001. Loss: 3.57769775390625.\n",
            "0: The an method method method method method method of method method on method method method method the method method method method. method method method\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.20\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.21\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.22\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.23\n",
            "  Batch   700  of  20,001. Loss: 6.671417236328125.\n",
            "0: The,The,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,,-,,,,,.,,, to,,.,, is. for (. on ( when (). (\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.23\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.24\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.25\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Batch   800  of  20,001. Loss: 5.3397698402404785.\n",
            "0: The the is the and the which\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.26\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.27\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.28\n",
            "\n",
            "  Average training loss: 0.29\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.29\n",
            "  Batch   900  of  20,001. Loss: 5.431040287017822.\n",
            "0: We also we we a, we we a we, our we we, we we we we our.We us..\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.29\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.30\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.31\n",
            "  Batch 1,000  of  20,001. Loss: 5.547893524169922.\n",
            "0: We introduce a new approach to consider a the results based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based basedbased based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based based basedbased based based based based based based based based based based based based based based based based based based based based based based based basedbased based based basedbased based based based based basedbased based based based based based based based based based based based based based based based based basedbased based based based based based based based\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.31\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.32\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.33\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.34\n",
            "  Batch 1,100  of  20,001. Loss: 4.734034061431885.\n",
            "0: We of of, how- we of we, we our of the, the, of\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.34\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.35\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.36\n",
            "  Batch 1,200  of  20,001. Loss: 4.470605373382568.\n",
            "0: In this paper our our paper we aim we this we aim this this our aim our our our\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.36\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.37\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.38\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Batch 1,300  of  20,001. Loss: 4.690426826477051.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: We the and we demonstrate theand We and our and demonstrate\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.39\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.40\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n",
            "\n",
            "  Average training loss: 0.41\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.42\n",
            "  Batch 1,400  of  20,001. Loss: 6.117832183837891.\n",
            "0: We, using, using of the using using we and techniques methods techniques techniques techniques.\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.42\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.43\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "  Batch 1,500  of  20,001. Loss: 5.71853494644165.\n",
            "0: We a a a method a a using a using for the method methods.\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.47\n",
            "  Batch 1,600  of  20,001. Loss: 4.430028438568115.\n",
            "0: A proposed paper proposes novel novel proposes novel proposes novel the novel method newof.ofofof-of\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.49\n",
            "  Batch 1,700  of  20,001. Loss: 6.5476298332214355.\n",
            "0: However, it is a has has has been a been a a is a.. is.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.50\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.51\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.52\n",
            "  Batch 1,800  of  20,001. Loss: 6.1256103515625.\n",
            "0: The paper is is- paper for method-- approach---the approach- approach-- method-based- method-based method-\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.53\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.54\n",
            "  Batch 1,900  of  20,001. Loss: 4.734808444976807.\n",
            "0: These two also also popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular popular\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.54\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.55\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.56\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.57\n",
            "  Batch 2,000  of  20,001. Loss: 5.002987384796143.\n",
            "0: We consider the for analysis on, analysis analysis analyses analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.57\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.58\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n",
            "\n",
            "  Average training loss: 0.59\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.60\n",
            "  Batch 2,100  of  20,001. Loss: 5.669808864593506.\n",
            "0: The this this paper a is the this this is this this this\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.60\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.61\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "  Batch 2,200  of  20,001. Loss: 5.98890495300293.\n",
            "0: We this we paper the a we a our a a a a novel model a- a model of... the\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.62\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.63\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.64\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Batch 2,300  of  20,001. Loss: 3.2659852504730225.\n",
            "0: Our investigate this investigate investigate method is is on., study\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.65\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.66\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "  Batch 2,400  of  20,001. Loss: 5.462156772613525.\n",
            "0: We prove our to a... to method- to- the results to..\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.67\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.68\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.69\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.70\n",
            "  Batch 2,500  of  20,001. Loss: 2.9872701168060303.\n",
            "0: The,, is is, the two the it is the not one a\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.70\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.71\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.72\n",
            "  Batch 2,600  of  20,001. Loss: 3.377201795578003.\n",
            "0: The model, model- approach approach, this propose- approach-, a approach\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.72\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.73\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.74\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.75\n",
            "  Batch 2,700  of  20,001. Loss: 5.479722499847412.\n",
            "0: The model for algorithm for algorithm for a method a ( a algorithm a the model algorithm model an. algorithm\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.75\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.76\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.77\n",
            "  Batch 2,800  of  20,001. Loss: 3.6929187774658203.\n",
            "0: In this we this address a on\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.77\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.78\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.79\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "  Batch 2,900  of  20,001. Loss: 5.499824523925781.\n",
            "0: The paper address paper an present paper problem the.\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.80\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.81\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.82\n",
            "  Batch 3,000  of  20,001. Loss: 3.679206132888794.\n",
            "0: It is is is a a is a is a is an an is for this this.. is of\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.82\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.83\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.84\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "  Batch 3,100  of  20,001. Loss: 6.124998569488525.\n",
            "0: The show the- shown the with the of show the- the- ofart.\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.85\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.86\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n",
            "\n",
            "  Average training loss: 0.87\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.87\n",
            "  Batch 3,200  of  20,001. Loss: 4.727360725402832.\n",
            "0: As the, the of the as are as is is not as the, the the the\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.88\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.89\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "  Batch 3,300  of  20,001. Loss: 5.333958148956299.\n",
            "0: The paper paper paper novel, novel novel the, novel, novel novel novel the novel the novel the novel.\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.90\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.91\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.92\n",
            "  Batch 3,400  of  20,001. Loss: 4.75711727142334.\n",
            "0: This this this algorithm proposed proposes propose a. and and algorithm algorithm\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.92\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.93\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.94\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.95\n",
            "  Batch 3,500  of  20,001. Loss: 4.603271007537842.\n",
            "0: We we, we,, methods. to\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.95\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.96\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 0.97\n",
            "  Batch 3,600  of  20,001. Loss: 4.230157852172852.\n",
            "0: This works we this we we we we we we we our we our on work work.\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.97\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.98\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 0.99\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.00\n",
            "  Batch 3,700  of  20,001. Loss: 7.111079216003418.\n",
            "0: We address address algorithm address this we address algorithm algorithm algorithm algorithms algorithm algorithm algorithm algorithms algorithms algorithms.\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.00\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.01\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.02\n",
            "  Batch 3,800  of  20,001. Loss: 4.8617844581604.\n",
            "0: We we our also our our our results results results. our on our results\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.02\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.03\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.04\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.05\n",
            "  Batch 3,900  of  20,001. Loss: 5.844161033630371.\n",
            "0: We propose a a a an propose a the we new new new new new\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.05\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.06\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "  Batch 4,000  of  20,001. Loss: 5.548970699310303.\n",
            "0: Some some some problems some some some some some some of some several methods methods methods methods methods.\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.07\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.08\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.09\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.10\n",
            "  Batch 4,100  of  20,001. Loss: 4.576646327972412.\n",
            "0: Such are are are have shown the been shown have been been shown performance shown on.\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.10\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.11\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "  Batch 4,200  of  20,001. Loss: 5.228146553039551.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: We is- of is is of of of two- of- and and and and of a\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.12\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.13\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.14\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.15\n",
            "  Batch 4,300  of  20,001. Loss: 4.4565935134887695.\n",
            "0: Finally, our study our our our our novel our we our our our our\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.15\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.16\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "  Batch 4,400  of  20,001. Loss: 4.250202178955078.\n",
            "0: We also the and- that that our of that is well well of data data dataset available.\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.17\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.18\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.19\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.20\n",
            "  Batch 4,500  of  20,001. Loss: 3.4356942176818848.\n",
            "0: Then these can a two a can can a a a two\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.20\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.21\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.22\n",
            "  Batch 4,600  of  20,001. Loss: 5.516355514526367.\n",
            "0: We present present a new we novel new a a novel novel novel propose new novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.22\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.23\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.24\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.25\n",
            "  Batch 4,700  of  20,001. Loss: 4.566927909851074.\n",
            "0: For a a this of the a,,- approach this- with the, of and with---to-- approach,---of a- of----- a a. a and.- asive approach we approaches----based--, and--based- and for, a-\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.25\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.26\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.27\n",
            "  Batch 4,800  of  20,001. Loss: 3.693479061126709.\n",
            "0: Our approach achieves the achieves a.,, for algorithm the technique.\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.27\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.28\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.29\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "  Batch 4,900  of  20,001. Loss: 4.611688613891602.\n",
            "0: We also a a a paper paper paper of a paper of a paper paper of paper paper paper paper paper paper paper paper\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.30\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.31\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.32\n",
            "  Batch 5,000  of  20,001. Loss: 5.392972946166992.\n",
            "0: This has is also been- method the has has also has been be\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.32\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.33\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.34\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "  Batch 5,100  of  20,001. Loss: 3.174640655517578.\n",
            "0: This addresses addresses address addresses addresses addresses addresses- on addresses of addresses addresses\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.35\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.36\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.37\n",
            "  Batch 5,200  of  20,001. Loss: 4.985827922821045.\n",
            "0: The paper the we explore the new novel new new new approach the new approach method we the\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.37\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.38\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.39\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "  Batch 5,300  of  20,001. Loss: 5.921975612640381.\n",
            "0: In this we we, we this we, we a a and the and a and, and,, this,,,,,, the,,, and,, and and,, and,,,,,,,,, and we, this,, a this,, and, on, on,,, and,, of and,,,,,,,,,,, and,,,,,,,--, and,,,,,,, and,,,,, and,,, a a,,,,, and,,,,,,-,,,,,,-, and,,,,,,,,,,,,,,, a,,,,,,,-,,,,,,,, on,,,-- we,- and,,,,,,,,,,,,,,,,,,,,,\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.40\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.41\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.42\n",
            "  Batch 5,400  of  20,001. Loss: 4.846991062164307.\n",
            "0: The results shows achieves achieves achieves achieves achieves achieves achieves achieves achieves achieves achieves achieves achieves achieves achieves achieves achieves achieves achieveof method- achieves achieves achieves achieves achieve- performance- performance----of-of achieveof achieves achieves performance- achieves performance--of-thetheforms- achievesofof-theofof- outperofofof performanceof method-art- outper outperof-ofof on achieves--theoftheofoftheof-the-ofofthe outper achievesofartof outper achieves-ofofart- on achievestheofthe- achievesofthe performance achieves achievesofofartoftheof achievesforms ontheofofofthe onartofofofofof-of-of-the--ofof-ofofthe methodoftheofformsofofoftheofofofofartthe-of on outper performance-ofofof-of-of--of achievesthe--ofofart-offormsof\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.42\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.43\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.44\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "  Batch 5,500  of  20,001. Loss: 3.9056825637817383.\n",
            "0: We propose the the the the this algorithm this the approach proposed algorithm proposed approach methodof of proposed\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.45\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.46\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.47\n",
            "  Batch 5,600  of  20,001. Loss: 5.094452857971191.\n",
            "0: Finally, the the the of the of are also the of the. the..-\n",
            "\n",
            "  Average training loss: 1.47\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.48\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.49\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.50\n",
            "  Batch 5,700  of  20,001. Loss: 3.907440662384033.\n",
            "0: Our proposed a proposes- approach avised a approach a for-visedvisedvisedvisedvisedvised.visedvisedvisedvisedvisedvisedvisedvisedvisedvised learning learningvisedvised-visedvisedvised-visedvisedvisedvisedvisedvised\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.50\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.51\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "  Batch 5,800  of  20,001. Loss: 5.572845458984375.\n",
            "0: Here, a, a a a for for presents a learningvisedvised learning (vised learning learning learning learning learning learning learning learning learning a ( (). learning learning learning learningvised learning learning learning. learning- learning)) (vised a learning)) learning learning) learn learning learning a for learning learning. learning? learningvised- learning learning learning learning and learning))?)., ( ( toL ( (avised learning for an learning in\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.52\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.53\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.54\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.55\n",
            "  Batch 5,900  of  20,001. Loss: 4.530460357666016.\n",
            "0: In paper, paper a network a-Net Networks Networks Networks Networks network- Networks Networks Networks Networks Networks networks Networks Networks Networks Networks Networks Networks Networks Networks Networks networks Networks Networks Networks Networksolution Networks Networks Networks Networks Networks Networks Networks Networks Networks networks ( networks Networks Networks Networks Networks ( Networks Networks Networks Networks Networksolution Networks Networks Networks Networks Networks Networksolutionolution Networksolution Networks Networks Networks networks Networks Networks Networks NetworksNet Networks Networks Networks Networks Networks Networks Networks Networks Networks Networks Networks Networks networks Networks Networks Networks Networksal Networks Networks Networks Networks Networks Networks Networks Networks Networks ( Networks Networks Networks Networks NetworksNet Networks Networks Networks\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.55\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.56\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.57\n",
            "  Batch 6,000  of  20,001. Loss: 6.3422980308532715.\n",
            "0: It the the the the model the and the of the the between between the and the between between and relationships the relationships of..\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.57\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.58\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.59\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "  Batch 6,100  of  20,001. Loss: 5.251880645751953.\n",
            "0: First, the results the a the the the the the a- the the the the of of- of\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.60\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.61\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.62\n",
            "  Batch 6,200  of  20,001. Loss: 6.277011871337891.\n",
            "0: This approach and we paper on the that we, we introduce approaches approach framework method.\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.62\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.63\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.64\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "  Batch 6,300  of  20,001. Loss: 5.395545482635498.\n",
            "0: We describe techniques effectiveness effectiveness and effectiveness of our effectiveness effectiveness effectiveness effectiveness effectiveness efficacy effectiveness effectiveness effectiveness and the the effectiveness state effectiveness effectiveness effectiveness effectiveness effectiveness.of effectiveness effectiveness\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.65\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.66\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n",
            "\n",
            "  Average training loss: 1.67\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.67\n",
            "  Batch 6,400  of  20,001. Loss: 5.0534987449646.\n",
            "0: We propose three a for. a a new a for for for\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.68\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.69\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "  Batch 6,500  of  20,001. Loss: 5.609199523925781.\n",
            "0: We propose a method method proposed to novel propose\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.70\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.71\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n",
            "\n",
            "  Average training loss: 1.72\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.73\n",
            "  Batch 6,600  of  20,001. Loss: 3.149286985397339.\n",
            "0: In this,,, we introduce a the. in, is in two\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.73\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.74\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.75\n",
            "  Batch 6,700  of  20,001. Loss: 5.923052787780762.\n",
            "0: The method paper a new method is method method method method method method method technique technique technique method procedure method technique technique method extraction technique technique technique technique technique technique technique technique technique method method. procedure\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.75\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.76\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.77\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.78\n",
            "  Batch 6,800  of  20,001. Loss: 4.381187915802002.\n",
            "0: The show results results the the show results the show results the the results results the the.\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.78\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.79\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.80\n",
            "  Batch 6,900  of  20,001. Loss: 6.6913228034973145.\n",
            "0: As, this we a model a a model a model model a models model model model model model of\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.80\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.81\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.82\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.82\n",
            "  Batch 7,000  of  20,001. Loss: 5.085777759552002.\n",
            "0: In these, we present two propose two two to two present two a this two. two two two two\n",
            "\n",
            "  Average training loss: 1.82\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.83\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.84\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.85\n",
            "  Batch 7,100  of  20,001. Loss: 4.36084508895874.\n",
            "0: The study on demonstrate. method of model onof method performance.\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.85\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.86\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "  Batch 7,200  of  20,001. Loss: 4.217722415924072.\n",
            "0: We also also also the also also the the performance performance performance performance the performance performance\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.87\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.88\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.89\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.90\n",
            "  Batch 7,300  of  20,001. Loss: 5.128934383392334.\n",
            "0: In work paper paper paper we we introduce that paper we we work proposed approach\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.90\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.91\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "  Batch 7,400  of  20,001. Loss: 3.5779969692230225.\n",
            "0: In approach approach,, approaches new approach approaches approach approaches new approaches approach approach new new new approach algorithm approaches approaches approaches, new propose approach models propose. methods existing new approach.\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.92\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.93\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.94\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.95\n",
            "  Batch 7,500  of  20,001. Loss: 2.475527286529541.\n",
            "0: However it-- the---- in- it to- of of from the,- the it the... the is.\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.95\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.96\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.97\n",
            "  Batch 7,600  of  20,001. Loss: 4.509225368499756.\n",
            "0: Con paper presents a paper propose a model a model of a a. of forA. model\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.97\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.98\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 1.99\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.00\n",
            "  Batch 7,700  of  20,001. Loss: 4.9476470947265625.\n",
            "0: The proposed is is problem-based model is is this- for is of. based\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.00\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.01\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.02\n",
            "  Batch 7,800  of  20,001. Loss: 7.482079029083252.\n",
            "0: We introduce to describe show that that that this of a of to approach approach approach approach approach approach approach of approach approach approach approach approach approach of approach approach approach. approach approach approach approaches approach approach approaches approach approach.\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.02\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.03\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.04\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "  Batch 7,900  of  20,001. Loss: 6.38108491897583.\n",
            "0: For proposed we we of a a new new that new new of new of the.\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.05\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.06\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.07\n",
            "  Batch 8,000  of  20,001. Loss: 5.817592620849609.\n",
            "0: Thus, the results results and both both the both both both both both both both both both both both both both both both both both both both both both both both both-of\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.07\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.08\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.09\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "  Batch 8,100  of  20,001. Loss: 5.712683200836182.\n",
            "0: The framework an is extension\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.10\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.11\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.12\n",
            "  Batch 8,200  of  20,001. Loss: 3.064180374145508.\n",
            "0: The experimental the of the of the the the of of performance on on\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.12\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.13\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.14\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "  Batch 8,300  of  20,001. Loss: 3.307913303375244.\n",
            "0: We present present novel novel novel novel of the and for and.\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.15\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.16\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.17\n",
            "  Batch 8,400  of  20,001. Loss: 6.5844502449035645.\n",
            "0: We use our our and validate our and datasets and. on datasets datasets. our\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.17\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.18\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.19\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.20\n",
            "  Batch 8,500  of  20,001. Loss: 4.815891265869141.\n",
            "0: The paper article- describes an an an an an an an an\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.20\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.21\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.22\n",
            "  Batch 8,600  of  20,001. Loss: 5.289182662963867.\n",
            "0: Theimental experiments the experiments experiments the experiments on the our experiments experiments experiments.. method experiments. of\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.22\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.23\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.24\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.25\n",
            "  Batch 8,700  of  20,001. Loss: 4.283451080322266.\n",
            "0: For this paper paper present present we present present propose to this to to this.\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.25\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.26\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.27\n",
            "  Batch 8,800  of  20,001. Loss: 5.045528411865234.\n",
            "0: However, this is a method of has been have been has to..\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.27\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.28\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.29\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "  Batch 8,900  of  20,001. Loss: 6.098029613494873.\n",
            "0: Here first, of first first first of first first the of of of. of\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.30\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.31\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "  Batch 9,000  of  20,001. Loss: 3.5404305458068848.\n",
            "0: We of this that of we a that that we the model the--scale----scale the the robust a robust model a ofscale-of-the of the framework and a the framework. model-resolution proposed--- robust..scale method-- reconstruction\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.32\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.33\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.34\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.35\n",
            "  Batch 9,100  of  20,001. Loss: 5.090850353240967.\n",
            "0: The paper proposed work the. approach.. the. is new\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.35\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.36\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "  Batch 9,200  of  20,001. Loss: 3.473435163497925.\n",
            "0: In this,, we, we we, we we propose propose present we problem the problem problem ( the problem problem ( problem a\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.37\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.38\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.39\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.40\n",
            "  Batch 9,300  of  20,001. Loss: 5.739968776702881.\n",
            "0: We also discuss further also discuss discuss.\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.40\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.41\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.42\n",
            "  Batch 9,400  of  20,001. Loss: 5.185845851898193.\n",
            "0: We paper the of of of, paper of a of of the and of and paper.\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.42\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.43\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.44\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.45\n",
            "  Batch 9,500  of  20,001. Loss: 3.4575746059417725.\n",
            "0: It code is an is for the for is for for the the\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.45\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.46\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.47\n",
            "  Batch 9,600  of  20,001. Loss: 4.744146823883057.\n",
            "0: We present this present this theoretical\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.47\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.48\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.49\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.50\n",
            "  Batch 9,700  of  20,001. Loss: 3.5198328495025635.\n",
            "0: This proposed framework is framework the framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.50\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.51\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.52\n",
            "  Batch 9,800  of  20,001. Loss: 4.841188430786133.\n",
            "0: Finally, is a a is method a is a a of, a paper a...\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.52\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.53\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.54\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "  Batch 9,900  of  20,001. Loss: 4.792115211486816.\n",
            "0: We also also on on datasets results results effectiveness the effectiveness proposed proposed.. proposed\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.55\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.56\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.57\n",
            "  Batch 10,000  of  20,001. Loss: 5.1260504722595215.\n",
            "0: Furthermore, the is a of of the is of.. also the also...\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.57\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.58\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.59\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.60\n",
            "  Batch 10,100  of  20,001. Loss: 5.513617515563965.\n",
            "0: The paper the the the the the the that the of of and of of problem.\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.60\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.61\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.62\n",
            "  Batch 10,200  of  20,001. Loss: 4.426176071166992.\n",
            "0: The paper discusses paper presents this to presented.\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.62\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.63\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.64\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.64\n",
            "  Batch 10,300  of  20,001. Loss: 5.093069076538086.\n",
            "0: The proposed experimental of and, that shows the the proposed, proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed the proposed proposed proposed proposed proposed. proposed proposed proposed\n",
            "\n",
            "  Average training loss: 2.64\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.65\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.66\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "  Batch 10,400  of  20,001. Loss: 5.317251205444336.\n",
            "0: Inimental results, results our results on results show of the the our method proposed method the the proposed proposed.., the. proposedforms.\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.67\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.68\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.69\n",
            "  Batch 10,500  of  20,001. Loss: 6.335792541503906.\n",
            "0: This paper presents presents presents presents is and and framework and a and and framework of of of.\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.69\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.70\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.71\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "  Batch 10,600  of  20,001. Loss: 4.6379499435424805.\n",
            "0: To our results evaluate our the approach the the of our show the of results.. results\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.72\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.73\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.74\n",
            "  Batch 10,700  of  20,001. Loss: 4.042344093322754.\n",
            "0: For a a,, propose,, we novel, we a a framework novel a, a, on-- paper- a- a propose framework--- we method for framework based---- the- framework. a framework framework framework--- method-, forsuper- framework proposed.-super-super for based method framework in.- in-super and framework-- propose---, propose- framework propose method---super-based the of----- propose framework, based method method and and---basedto asuper methodative- proposearial,---ative-to---ofarial-arial-----arial-arialbasedbasedarialative method- gener on a-arial a framework weativearial forarial based a--arial based--,arial an-- aarial propose-arialarial-arialarialto-arialarialarial-- aarial networkarialative variarial\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.74\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.75\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.76\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.77\n",
            "  Batch 10,800  of  20,001. Loss: 3.8847568035125732.\n",
            "0: The proposed the of of proposed is.\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.77\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.78\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "  Batch 10,900  of  20,001. Loss: 6.8275227546691895.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: This paper paper addresses that that that is that that is that that an presents presents that and is an an...\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.79\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.80\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.81\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.82\n",
            "  Batch 11,000  of  20,001. Loss: 4.255876064300537.\n",
            "0: the we paper, the we this a a new in we, in in in, and- propose in of paper in paper. the classification object.- are.- in- of inin. this- is the proposed object applications- a paper.- of--in. in. the,- we- inbased in modeling- of- is in model, in\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.82\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.83\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "  Batch 11,100  of  20,001. Loss: 5.467767238616943.\n",
            "0: Many approaches other works other the that on works on other-- other works works other outperformsformsformsforms outperforms outper-form datasets otherformsforms---formsformsformsforms--of outper betterthe-forms outperforms other--- outperartform existing-formsthe approaches outperformsthe-- outper otherthe---of-thetheforms approaches-the-thethethe- outper-the----- than- outper datasetsthethe--forms-- outperthetheform- than-of the- onthe-the-the-of--- state-the- other approaches--formsformsthe-formsthetheart- than-the-thethe--thethethethe-thethethethe--theofthe-- outper- approaches-forms outper otherthetheartthethe-forms outperthetheofthethethe-thethe-oftheformsthe-thethe approaches-\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.84\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.85\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.86\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.87\n",
            "  Batch 11,200  of  20,001. Loss: 6.216108798980713.\n",
            "0: In this work, we work work, paper we paper that that- two on outper- two-- existing-the-of-- that-- method-of- two- previous--- on-- outper- our a--- two the-- methodsthe- outper-the-forms----the showof-the- the- methods- ourthe show ouroftheof both approaches-. the-art--the-art- ourthe- outper than--oftheformtheforms-theart- proposed-the---ofthe outperthe-- methods-- methods outper--the- methodthe-thethe- methods outper two- methods outperthe-the-art-the- methodsartofthethe ourthe- outperthe--forms outper the--art----the- theofartthethe outper approachesthe and. previousthethe-thethethe--- methods\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.87\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.88\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.89\n",
            "  Batch 11,300  of  20,001. Loss: 3.8864030838012695.\n",
            "0: The framework is. algorithm of our of- framework of algorithm algorithm.. algorithm our\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.89\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.90\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.91\n",
            "\n",
            "  Average training loss: 2.91\n",
            "  Batch 11,400  of  20,001. Loss: 4.070977687835693.\n",
            "0: They,, the, we are are proposed are,. proposed,,.,, proposed proposed.\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.92\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.93\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.94\n",
            "  Batch 11,500  of  20,001. Loss: 4.453065395355225.\n",
            "0: The proposed and proposed in effectiveness effectiveness of and in the effectiveness. effectiveness proposed proposed\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.94\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.95\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "  Batch 11,600  of  20,001. Loss: 4.4647440910339355.\n",
            "0: First, we we paper, first show in paper in an in in paper first this work problem in problem in problem this vision. problem.\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.96\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.97\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.98\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 2.99\n",
            "  Batch 11,700  of  20,001. Loss: 4.621393203735352.\n",
            "0: We propose propose we, approach evaluate proposed of evaluate evaluate evaluate approach approach approach approach approach approach approach approach of approach approach\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 2.99\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.00\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "  Batch 11,800  of  20,001. Loss: 4.618688106536865.\n",
            "0: In particular a we method non method method the of non method method method non method method method method method method method method method method method method method method method method method method method method method method method method method method method method method\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.01\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.02\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.03\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.04\n",
            "  Batch 11,900  of  20,001. Loss: 4.9509477615356445.\n",
            "0: The main the is is is is is the is the main main main main this.\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.04\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.05\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.06\n",
            "  Batch 12,000  of  20,001. Loss: 6.394539833068848.\n",
            "0: This paper work this a this paper work work a\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.06\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.07\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.08\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "  Batch 12,100  of  20,001. Loss: 4.0100998878479.\n",
            "0: The dataset evaluated is dataset benchmark the. challenging\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.09\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.10\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.11\n",
            "  Batch 12,200  of  20,001. Loss: 3.760122299194336.\n",
            "0: In the the the, the, to results we results the show it--- show that algorithm algorithm.\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.11\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.12\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.13\n",
            "\n",
            "  Average training loss: 3.14\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "  Batch 12,300  of  20,001. Loss: 6.580977439880371.\n",
            "0: The experiments show of proposed proposed on\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.14\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.15\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.16\n",
            "  Batch 12,400  of  20,001. Loss: 8.4012451171875.\n",
            "0: However, this novel of novel propose novel a a in in novel.\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.16\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.17\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n",
            "\n",
            "  Average training loss: 3.18\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "  Batch 12,500  of  20,001. Loss: 4.266619682312012.\n",
            "0: We goal this we goal, we goal we this goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal objective goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal objective goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.19\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.20\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.21\n",
            "  Batch 12,600  of  20,001. Loss: 5.183177947998047.\n",
            "0: The proposed proposed the proposed proposed proposed proposed the proposed proposed..\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.21\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.22\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.23\n",
            "  Batch 12,700  of  20,001. Loss: 5.423475742340088.\n",
            "0: Then, the trained to to and proposed train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.23\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.24\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.25\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "  Batch 12,800  of  20,001. Loss: 5.541379451751709.\n",
            "0: The dataset dataset the the dataset dataset of in in dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset the the dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset the dataset dataset dataset in dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset the dataset dataset the dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.26\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.27\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.28\n",
            "  Batch 12,900  of  20,001. Loss: 5.295485496520996.\n",
            "0: We show the the the on results the our the that the the we show this this\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.28\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.29\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.30\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.31\n",
            "  Batch 13,000  of  20,001. Loss: 5.525580883026123.\n",
            "0: We present theical mathematical of of of of of approach Bay of networks of networks networks networks networksesian networks networks networks networks networksalesianesians networks networks networksolution Bay networks networks networks networks networks networks networks networks networks networks networks network networksesian networks networksistic models networksistic networksesian networks networks networks networks neural networksesianesian inference neural networks networks.esian. of networks networks neural networksesianisticistic networks networks networks networksesianesian networks ofesian networks networksesianesian networks networks of networksesian these networks networks networks networks networks networksistic networks networksesian networks networks networks networks belief networksesian networks networksesianesian networks networks of inference.esian causal networks networks Bayesian causal. these of networks networks networks networks networks networks networks networks (s networks Bayesian Bay networks networks of ( networksal networks the networks networksesian networks networks networks networks neuralolution networks networks Bayesianal causal networks networks networksesian networks the neural networks) networks models networksal networks networks networks networksesians\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.31\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.32\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "  Batch 13,100  of  20,001. Loss: 3.428279161453247.\n",
            "0: This is is is this is first and and this is this and this and this this proposed this this and this.\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.33\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.34\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.35\n",
            "  Batch 13,200  of  20,001. Loss: 4.545055866241455.\n",
            "0: We apply to apply a to to address an an to address address..\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.35\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.36\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.37\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.38\n",
            "  Batch 13,300  of  20,001. Loss: 4.2716803550720215.\n",
            "0: The framework paper paper,,,, we,, approach, multi approach approach approach approach approaches. approaches approaches approaches\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.38\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.39\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.40\n",
            "  Batch 13,400  of  20,001. Loss: 5.09928035736084.\n",
            "0: A large large method a large large with largescale, large large large of proposed proposed outper of the existing theformsart proposed severalformsformsof stateforms existing state state of- state a datasets withformsformsartformsforms state stateartformsforms state state state state stateofofofofformsforms existing state outperformsforms with stateart method our ourformsforms state aforms of-artforms state aformsforms state state state stateformsformsforms existingforms datasetsforms outperformsformsforms,theformstheformsformsforms method existing method several existing outper proposed methods existing proposed outperforms proposed-formsformsforms statethe stateformsformsforms state-forms- on aofforms largeformstheartforms existing the outperformsforms state proposed proposed state theformsforms state-forms existing outperformsformsformsformsforms state-,formsformsformsformsforms proposedformsformsforms state stateforms large methodsforms statethe state stateforms of datasetsforms state state outper state-formsforms state\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.40\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.41\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.42\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.43\n",
            "  Batch 13,500  of  20,001. Loss: 5.347660541534424.\n",
            "0: The algorithm of of with the of algorithm of the algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm the algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm the algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm the algorithm algorithm algorithm algorithm the algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.43\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.44\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.45\n",
            "  Batch 13,600  of  20,001. Loss: 4.400411605834961.\n",
            "0: For all new,, we we we a novel fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast fast\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.45\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.46\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.47\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.48\n",
            "  Batch 13,700  of  20,001. Loss: 5.615633487701416.\n",
            "0: However, of of the model is our of our of our the the...\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.48\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.49\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.50\n",
            "  Batch 13,800  of  20,001. Loss: 3.4692935943603516.\n",
            "0: We propose,, we propose, we,, we propose propose, we propose, a\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.50\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.51\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.52\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.52\n",
            "\n",
            "  Average training loss: 3.53\n",
            "  Batch 13,900  of  20,001. Loss: 5.09889030456543.\n",
            "0: It has ( an an to- tobased tobased thisbasedbasedbasedbased based based popularbasedbasedbasedbased popular popular popular popularbased approach based)based popularbasedbaseduristicuristic popularbasedbased popular\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.53\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.54\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.55\n",
            "  Batch 14,000  of  20,001. Loss: 4.975993633270264.\n",
            "0: This and approach and method- and an algorithm algorithm- method method method algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithms algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithms algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithms algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithms algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.55\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.56\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.57\n",
            "  Batch 14,100  of  20,001. Loss: 5.167832851409912.\n",
            "0: Then we we consider investigate the of the an approach an of an an proposed...\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.57\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.58\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.59\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.60\n",
            "  Batch 14,200  of  20,001. Loss: 4.762509346008301.\n",
            "0: We conduct two two two the two and.. two and\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.60\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.61\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.62\n",
            "  Batch 14,300  of  20,001. Loss: 5.840254306793213.\n",
            "0: The approach approach method- approach- a------ method on on an. and with---- is withbased-- for methodbased.---\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.62\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.63\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.64\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.65\n",
            "  Batch 14,400  of  20,001. Loss: 5.5554094314575195.\n",
            "0: We present a a novel. novel a. for. a.\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.65\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.66\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.67\n",
            "  Batch 14,500  of  20,001. Loss: 4.539572715759277.\n",
            "0: We extend to extend applic applic applic approach applic applic to applic applic applic applic applic applicability applicabilityability applic applicabilityability applic applic applic applic approach applic approach demonstrate. applic.. proposed\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.67\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.68\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.69\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "  Batch 14,600  of  20,001. Loss: 4.624574184417725.\n",
            "0: The experimental indicate show results indicate show experimental shows the experimental that show experimental experiments..\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.70\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.71\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.72\n",
            "  Batch 14,700  of  20,001. Loss: 4.102044582366943.\n",
            "0: The new we, the introduce new new new the propose introduce method method method proposed..\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.72\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.73\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.74\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "  Batch 14,800  of  20,001. Loss: 6.576483726501465.\n",
            "0: A the algorithm is algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm the algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithms\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.75\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.76\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.77\n",
            "  Batch 14,900  of  20,001. Loss: 3.956972599029541.\n",
            "0: The\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.77\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.78\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.79\n",
            "  Batch 15,000  of  20,001. Loss: 4.975656986236572.\n",
            "0: A, a for a for, is analysis analysis for a a analysis analysis analysis analysis..\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.79\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.80\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.81\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.82\n",
            "  Batch 15,100  of  20,001. Loss: 4.295679092407227.\n",
            "0: The\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.82\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.83\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.84\n",
            "  Batch 15,200  of  20,001. Loss: 5.135076999664307.\n",
            "0: Using\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.84\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.85\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.86\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.87\n",
            "  Batch 15,300  of  20,001. Loss: 4.799190521240234.\n",
            "0: Now\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.87\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.88\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.89\n",
            "  Batch 15,400  of  20,001. Loss: 4.378037452697754.\n",
            "0: In this we work the we the algorithm the the the for method. method.. method method method method method\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.89\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.90\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.91\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.91\n",
            "  Batch 15,500  of  20,001. Loss: 3.8594343662261963.\n",
            "0: F the is is a of the the the F the VL\n",
            "\n",
            "  Average training loss: 3.91\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.92\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.93\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "  Batch 15,600  of  20,001. Loss: 5.725173473358154.\n",
            "0: The the the the the of the each each each, each, each each each each each each each each each each each each each each each, each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each each, each each each each each each each each each each each the each each each each each each each each each each each each each each each each each each each each each each each each each each each, each each each each each each each each each each each each each each each each each each each each each each each each each, each each each each each each each each each each each each\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.94\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.95\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.96\n",
            "  Batch 15,700  of  20,001. Loss: 4.388754844665527.\n",
            "0: To this,, this work this a of we work.\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.96\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.97\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.98\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 3.99\n",
            "  Batch 15,800  of  20,001. Loss: 3.1948654651641846.\n",
            "0: This paper this paper paper this review in paper this.. paper.. paper paper this paper.\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 3.99\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.00\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.01\n",
            "  Batch 15,900  of  20,001. Loss: 4.195741176605225.\n",
            "0: However this the this work the the to approach the, this the algorithm algorithm algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms the algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms techniques algorithms algorithms algorithms algorithms algorithms algorithms algorithms the algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithm algorithms algorithms algorithms algorithm algorithm algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms techniques algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms the algorithm algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms algorithms\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.01\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.02\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.03\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.04\n",
            "  Batch 16,000  of  20,001. Loss: 4.89238977432251.\n",
            "0: In this paper,, we propose two propose two two two two two two two.\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.04\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.05\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "  Batch 16,100  of  20,001. Loss: 3.560922622680664.\n",
            "0: However, the on proposed proposed proposed the proposed effectiveness on. state effectiveness proposed\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.06\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.07\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.08\n",
            "  Batch 16,200  of  20,001. Loss: 6.426080703735352.\n",
            "0: These are results results that that of that of results and state the are that that\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.08\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.09\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.10\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "  Batch 16,300  of  20,001. Loss: 4.642073154449463.\n",
            "0: Our network method is method proposed is proposed consists proposed methods proposed proposed proposed\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.11\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.12\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.13\n",
            "  Batch 16,400  of  20,001. Loss: 5.448152542114258.\n",
            "0: The algorithm-- algorithm that algorithm algorithm algorithm algorithm is- algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm.\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.13\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.14\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.15\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.16\n",
            "  Batch 16,500  of  20,001. Loss: 6.182981967926025.\n",
            "0: Our paper presents we,,, we, study study, and analyze analysis analyses...\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.16\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.17\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.18\n",
            "  Batch 16,600  of  20,001. Loss: 5.146176338195801.\n",
            "0: We propose propose two two propose methods\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.18\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.19\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.20\n",
            "\n",
            "  Average training loss: 4.21\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "  Batch 16,700  of  20,001. Loss: 4.19788122177124.\n",
            "0: The experimental demonstrate the the the proposed the existing results the the proposed---art proposed---nessness of robust- results-ness existing proposed the proposed existing-art theofart the- proposed of-of demonstrate- method method methods the of-- ofart state-art the the-the-- the-ofart- state-- theness thethethe state- the-art-the- theof demonstrate state-of the existing-art of- thetheofartart--the- state-art of of--- arttheforms- existing-theness existing results-theart- state- the the existing method state state-artthe- existing---- of proposed stateart- state artof-theart stateart-thenessthe proposed theofart--art existing existingthe- of- existing existingthe of-art of thetheart. theof existingthethe-the-art-the state\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.21\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.22\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.23\n",
            "  Batch 16,800  of  20,001. Loss: 5.319082260131836.\n",
            "0: This code paper addresses the of the of on the of of. of\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.23\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.24\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.25\n",
            "  Batch 16,900  of  20,001. Loss: 4.965581893920898.\n",
            "0: The new new new a new new a method new method new method method method method method method... method method method\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.25\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.26\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.27\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "  Batch 17,000  of  20,001. Loss: 5.202658176422119.\n",
            "0: We propose to to new we method method framework framework benchmark to benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark benchmark\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.28\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.29\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.30\n",
            "  Batch 17,100  of  20,001. Loss: 3.0168685913085938.\n",
            "0: The study in in problem of problem of problem a problem of problem problems problems problems problems problems problems problems problems problems problems problems problems problems problems problems.\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.30\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.31\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.32\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.33\n",
            "  Batch 17,200  of  20,001. Loss: 5.405601978302002.\n",
            "0: We illustrate an of the two in an an\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.33\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.34\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.35\n",
            "  Batch 17,300  of  20,001. Loss: 5.647895812988281.\n",
            "0: Our results results results results results that that results that results results results.\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.35\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.36\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.37\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.37\n",
            "  Batch 17,400  of  20,001. Loss: 6.3210129737854.\n",
            "0: We then is. the the problem to\n",
            "\n",
            "  Average training loss: 4.37\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.38\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.39\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.40\n",
            "  Batch 17,500  of  20,001. Loss: 5.1244401931762695.\n",
            "0: This paper paper proposes a to paper that that hypothesis on that hypothesis hypothesis hypothesis hypothesis hypothesis hypothesis\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.40\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.41\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.42\n",
            "  Batch 17,600  of  20,001. Loss: 6.26529598236084.\n",
            "0: The main of the in the the of of the the the. the\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.42\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.43\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.44\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "  Batch 17,700  of  20,001. Loss: 4.850964069366455.\n",
            "0: Furthermore, we we, focus a on on the focus on focus on focus the method.\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.45\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.46\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.47\n",
            "  Batch 17,800  of  20,001. Loss: 4.055968284606934.\n",
            "0: The models the the are of that the the are are models the models models for.\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.47\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.48\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.49\n",
            "\n",
            "  Average training loss: 4.50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "  Batch 17,900  of  20,001. Loss: 6.015502452850342.\n",
            "0: The proposed show we show model to can of can- to- improve improve can improve improve improve improve improve improve proposed improve improve improve improve improve improve performance improve improve. improve improve improve improve improve improve improve improve improve improve improve improve improve\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.50\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.51\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.52\n",
            "  Batch 18,000  of  20,001. Loss: 3.867124557495117.\n",
            "0: These findings the by by by of proposed the the\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.52\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.53\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.54\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.54\n",
            "  Batch 18,100  of  20,001. Loss: 5.457679748535156.\n",
            "0: In article work, we present for work for in for of work work..\n",
            "\n",
            "  Average training loss: 4.54\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.55\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.56\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "  Batch 18,200  of  20,001. Loss: 3.7225489616394043.\n",
            "0: The work paper approach of of approach of of of the\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.57\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.58\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "  Batch 18,300  of  20,001. Loss: 4.959021091461182.\n",
            "0: This approach is is approach.\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.59\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.60\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.61\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "  Batch 18,400  of  20,001. Loss: 5.349801540374756.\n",
            "0: Pon the is on and the and)) is is is and model ( is\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.62\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.63\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "  Batch 18,500  of  20,001. Loss: 4.6442179679870605.\n",
            "0: Experimental proposed the the method method the of proposed. method method method proposed our the proposed proposed proposed. proposed proposed proposed. method proposed proposed proposed proposed proposed proposed method our proposed proposed proposed proposed method proposed method method our proposed proposed proposed proposed proposed proposed proposed method proposed proposed proposed proposed method proposed proposed proposed proposed method proposed proposed proposed proposed our proposed proposed proposed proposed proposed proposed proposed. approach proposed\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.64\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.65\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.66\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.67\n",
            "  Batch 18,600  of  20,001. Loss: 5.69284200668335.\n",
            "0: In this, paper paper,, propose the new novel to thesupersupersupersupersupersupersupersupersupersupersuper thesupersupersupersupersupersupersupervisedsupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupervisedsupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupervisedsupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupervisedsupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupervisedsupersupersupersupersupersupersupervisedsupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupersupervisedvisedsupersupersupersupervisedsupersupersupersupersupersupersupersupersupersupersupersupervisedsupersupersupersupersupersupersupervisedsupersupersupersupersupersupersupersupervisedsupersupersupersupersupersupersuper\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.67\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.68\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.69\n",
            "  Batch 18,700  of  20,001. Loss: 4.160608291625977.\n",
            "0: Deep- that- that- that that neural that that that network neural- that on that neuralal networknetwork neural onolution network on networkal networks networknetwork neural network network network network that network network network networkolution network network networks neural networks network networks neuralolution neural that neural network network network network network network network neural network network- network network network neural networkolution networks neural neural network network network network network network network network networknetwork network networks neural neural neural deep network network neural conv conv network of network deep networks network networks network networkal network neural neural neural neural based network on network network deep networks that--- networks neural network network network network network network networksolution neural network neural neural networks that network network- neurallevel deep network network- network network on neural network networkal network- neural network network neural network neural networks network network network networknetwork network network neural deep neural network conv structure network network network network network network network network network network model network based network network networkal on neural networks neural deep networks\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.69\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.70\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.71\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "  Batch 18,800  of  20,001. Loss: 5.598791122436523.\n",
            "0: We define to to--- to model model and) a describe for model to model model model for model model model model model model model model model. model model model model model model model model\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.72\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.73\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.74\n",
            "  Batch 18,900  of  20,001. Loss: 4.798295974731445.\n",
            "0: One method of is the our our our method data on on the our data. data data\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.74\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.75\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "  Batch 19,000  of  20,001. Loss: 4.458259582519531.\n",
            "0: In this work, work work work we this previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous work previous work previous previous work previous previous this previous work.\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.76\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.77\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.78\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "  Batch 19,100  of  20,001. Loss: 5.145211696624756.\n",
            "0: H, paper we, we,, paper H we we, H a H of, a, we a of of K a deep on on of of of deep-, the of on of- deep of of- of neural of of deep learningal deepal of network deep deep learning of of deeptrainedvisedvised fully training trainingolution a deep network deep neural deep ofNNets of of conv for of deep of- fully training deep deep of CNN learning, of deep,ets learning deep deepvised deepsuper deep modeltrained deep- model deep deep deep deep of deep for network deep deep deep- learning learning conv a deep- deep deep deep deepNN- a fullyolutionolution deep deep learning trainingNet deep fullyNN learning deepolution oftrained training deep deep deep model deepsuper deep fully deep of convolution network deep deep deep a deep fullyal learning deep deep deepNNNN deepsuper deep deep learning deep- deepNetalal thevised deepNN deep deep learning deep deep deep network\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.79\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.80\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.81\n",
            "  Batch 19,200  of  20,001. Loss: 4.366238117218018.\n",
            "0: The proposed approach approach that- the the the approach, that is approach approach approach approach is\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.81\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.82\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.83\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 19,300  of  20,001. Loss: 3.704373836517334.\n",
            "0: The proposed method method model that proposed algorithm-- algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm proposed algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm the algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.84\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.85\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 4.86\n",
            "  Batch 19,400  of  20,001. Loss: 4.171446323394775.\n",
            "0: Furthermore, we we we we the present model a new model a a model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model a model model model model model model model model model model model model model model model model model model model model model new model model model model model model model of models model model model model model model model model model model the model model a model model model model model model model model model model model model model model model model model model model model model model model model model model model model model models model model model model model model a model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.86\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.87\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.88\n",
            "  Batch 19,500  of  20,001. Loss: 4.7319769859313965.\n",
            "0: The algorithm uses algorithm algorithm algorithm algorithm uses algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm the algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm\n",
            "\n",
            "  Average training loss: 4.88\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.89\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.90\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "  Batch 19,600  of  20,001. Loss: 5.039397716522217.\n",
            "0: We also the also that-- our to our our and also-- our--form-the- our--of--formsof our-artthe---the-artthe-art.-----the- state.---the-the---artthe-the-- state theof-the-artofart---- ourthe- our--the state--art-thethe-art--the--artart-the. otherart.art----theartofthe state-the--theart-thethe--the-ofartthe--- statethe--art-theart- other--the--the-of-art-of state-the-the--the-art-----of outper----ofthe- toart----art-- outper-- other-\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.91\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.92\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 4.93\n",
            "  Batch 19,700  of  20,001. Loss: 4.611883640289307.\n",
            "0: The two is two is a the two to the the to and is. is.\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.93\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.94\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.95\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 4.96\n",
            "  Batch 19,800  of  20,001. Loss: 4.895796298980713.\n",
            "0: It also of it it the also also the, the this also also the the to to of the the of this.\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.96\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.97\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 19,900  of  20,001. Loss: 4.927008628845215.\n",
            "0: The system are the are is are that by the are by the..\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.98\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 4.99\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n",
            "\n",
            "  Average training loss: 5.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.00\n",
            "  Batch 20,000  of  20,001. Loss: 4.321033477783203.\n",
            "0: But show show results are these be obtained that obtained obtained obtained be obtained obtained obtained obtained obtained. obtained.\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.01\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.02\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "  Batch   100  of  20,001. Loss: 4.302534580230713.\n",
            "0: Image is this is in in is image to is image is image image.\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.03\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.04\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.05\n",
            "  Batch   200  of  20,001. Loss: 4.330041408538818.\n",
            "0: However it is are and to to is to is and are and are\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.05\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.06\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   300  of  20,001. Loss: 5.01981782913208.\n",
            "0: We\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.07\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.08\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.09\n",
            "  Batch   400  of  20,001. Loss: 4.088836193084717.\n",
            "0: For these are this we and these are are these they and their\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.09\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.10\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "  Batch   500  of  20,001. Loss: 3.940502882003784.\n",
            "0: In this,,,,,,, a a, a of, of a a. a a, a a,\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.11\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.12\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.13\n",
            "  Batch   600  of  20,001. Loss: 4.315600872039795.\n",
            "0: Our findings findings findings the the findings our discuss our theoretical theoretical theoretical theoretical theoretical theoretical\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.13\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.14\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.15\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.16\n",
            "  Batch   700  of  20,001. Loss: 3.3418760299682617.\n",
            "0: A problem of is of to to a- is be the the-- the the the is then a the proposed proposed...\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.16\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.17\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.18\n",
            "  Batch   800  of  20,001. Loss: 3.169015407562256.\n",
            "0: We present and that that that that that-- novel that it that that that that it is framework it is framework-, and framework framework structure structure- framework framework and framework-- that frameworkbased framework framework. framework framework. framework framework framework framework..\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.18\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.19\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   900  of  20,001. Loss: 4.253810882568359.\n",
            "0: We have using on on on validated empir using the tested the were..\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.20\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.21\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,000  of  20,001. Loss: 3.068899393081665.\n",
            "0: We provide experimental results results results results of results of of results experimental\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.22\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.23\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "  Batch 1,100  of  20,001. Loss: 3.3379337787628174.\n",
            "0: The main the problem of is of main main is of main main main main main main main main main main main main main main main main. main main main main\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.24\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.25\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n",
            "\n",
            "  Average training loss: 5.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "  Batch 1,200  of  20,001. Loss: 2.4174835681915283.\n",
            "0: In this work, paper we, we new new, new, new new new new new\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.27\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.28\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "  Batch 1,300  of  20,001. Loss: 4.142204761505127.\n",
            "0: We demonstrate show show of of of the the the. the that to..\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.29\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.30\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "  Batch 1,400  of  20,001. Loss: 4.454573154449463.\n",
            "0: A common this, is is is one of of is the. of. is of.\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.31\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.32\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "  Batch 1,500  of  20,001. Loss: 3.3563427925109863.\n",
            "0: The model our was was was was was our was was was was was was system.\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.33\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.34\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "  Batch 1,600  of  20,001. Loss: 4.317004203796387.\n",
            "0: A new new of of new methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.35\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.36\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,700  of  20,001. Loss: 3.706988573074341.\n",
            "0: We present the the approach approach a approach approach of approach approach approach the.\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.37\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.38\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.39\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,800  of  20,001. Loss: 4.43691873550415.\n",
            "0: Our findings two two are two findings..\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.40\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.41\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "  Batch 1,900  of  20,001. Loss: 3.8334245681762695.\n",
            "0: The are of are the provided are are described of are of proposed are of proposed..\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.42\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.43\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  20,001. Loss: 5.226353168487549.\n",
            "0: We provide our our our our our our demonstrate our validate extensive- to our- our our our several several to and our demonstrate the- our that effectiveness the and several our our to on our effectiveness and- demonstrate and- to our- datasets demonstrate-of effectiveness our- several- both our on on several our our our- and- both demonstrate our our- and our- experiments of-world several the our our the effectiveness- datasets methodworld demonstrate ourworldworld-world effectivenessworldworld effectiveness to two dataset to and- on two- the our-world andworld- to dataset andof approach benchmark- both two our demonstrate dataset on datasetsworld- demonstrate- and toworld synthetic onworld theworld several ourworldtheworldworld several datasetsworldworld datasetsthethe dataset and real on the the approachthe several and datasets datasets on on- and-world---- on datasetworld-of-world the--worldworldworld-world several datasets benchmark- dataset---\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.44\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.45\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "  Batch 2,100  of  20,001. Loss: 4.6631646156311035.\n",
            "0: This analysis the analysis the that analysis the of analysis the analysis the analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.46\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.47\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "  Batch 2,200  of  20,001. Loss: 3.7380170822143555.\n",
            "0: We find that that that show that that show that that suggest that that suggest that our our\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.48\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.49\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.50\n",
            "\n",
            "  Average training loss: 5.51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.51\n",
            "  Batch 2,300  of  20,001. Loss: 5.149639129638672.\n",
            "0: It uses in uses the to the one in in in one one in most most in most.\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.51\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.52\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "  Batch 2,400  of  20,001. Loss: 3.8294577598571777.\n",
            "0: This work discusses a framework using framework using. framework framework a framework\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.53\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.54\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,500  of  20,001. Loss: 4.908599376678467.\n",
            "0: The resulting algorithm is algorithm algorithm algorithm is algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm. algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.55\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.56\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "  Batch 2,600  of  20,001. Loss: 4.73516845703125.\n",
            "0: In this paper paper, we a, investigate a propose this method this method method method method.\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.57\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.58\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "  Batch 2,700  of  20,001. Loss: 5.216814041137695.\n",
            "0: We show our experiments our the of the our of show method...\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.59\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.60\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.61\n",
            "\n",
            "  Average training loss: 5.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,800  of  20,001. Loss: 4.390539169311523.\n",
            "0: Image experiments are the of-- and and evaluated on\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.62\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.63\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.64\n",
            "  Batch 2,900  of  20,001. Loss: 4.199113368988037.\n",
            "0: They also be can can a a a a be to be. estim be\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.64\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.65\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "  Batch 3,000  of  20,001. Loss: 5.931262969970703.\n",
            "0: Finally, we the propose the we the the on the the- to approach the the- on approach the to approach the approach to approach approach approach approach\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.66\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.67\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "  Batch 3,100  of  20,001. Loss: 5.459340572357178.\n",
            "0: Current existing existing for is existing existing systems of existing existing existing existing existing existing existing existing existing existing. existing. existing existing\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.68\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.69\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,200  of  20,001. Loss: 4.831300735473633.\n",
            "0: To this paper paper paper review issue issue we\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.70\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.71\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.72\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.73\n",
            "  Batch 3,300  of  20,001. Loss: 5.659063816070557.\n",
            "0: In this paper paper paper we, a propose a paper propose this. this\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.73\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.74\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3,400  of  20,001. Loss: 4.45755672454834.\n",
            "0: This paper presents a for a for deep- a\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.75\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.76\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.77\n",
            "  Batch 3,500  of  20,001. Loss: 3.968064546585083.\n",
            "0: Recently, this, a we that that that that this. a this that. that.\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.77\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.78\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "  Batch 3,600  of  20,001. Loss: 3.7884609699249268.\n",
            "0: The results results also results results results also proposed also.\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.79\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.80\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "  Batch 3,700  of  20,001. Loss: 5.847156524658203.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: There\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.81\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.82\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.83\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "  Batch 3,800  of  20,001. Loss: 3.93998122215271.\n",
            "0: The performance performance performance performance performance performance of performance performance performance of performance performance performance performance performance performance performance of performance of performance performance of performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.84\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.85\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.86\n",
            "  Batch 3,900  of  20,001. Loss: 5.50543212890625.\n",
            "0: In, paper we, we we we we- algorithm a a model model model model model. model model model model model model\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.86\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.87\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "  Batch 4,000  of  20,001. Loss: 2.812822103500366.\n",
            "0: In, paper a propose propose a method, propose methods method method method method method novel method method method proposed method method method method method method method method method method method method novel method proposed method method proposed method methods novel method method method method method method method method method method method method method method method method proposed method method method method method method method method method method method method method method method method method method for method method method method method method method method method method method methods method method method method method. novel method methods method method method method method.. method method method method method method method method method method method method method method method method method method method proposed method method method method method method method method method method method method method method method method method method method novel method method method method method method method method method proposed method method method method method method method method method method method method novel method method method for method method method method for method for. novel method method method method method method method method method method method method method method method method novel\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.88\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.89\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "  Batch 4,100  of  20,001. Loss: 2.6938555240631104.\n",
            "0: These algorithms the to algorithms used and algorithms algorithms to algorithms and algorithms algorithms algorithms. algorithms algorithms algorithms algorithms algorithms\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.90\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.91\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "  Batch 4,200  of  20,001. Loss: 4.369495391845703.\n",
            "0: Our results results results shows the two- two on.\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.92\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.93\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.94\n",
            "  Batch 4,300  of  20,001. Loss: 4.701094150543213.\n",
            "0: The framework based the the based framework based using using framework framework framework framework framework framework.\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.94\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.95\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 4,400  of  20,001. Loss: 3.843243360519409.\n",
            "0: In this paper, a, problem propose a- ( ( ( problem (ov (ial))ial problem relational relational) modeling problem relational relational relational relational for relational relational problem relational) relational relational relational problem relational relational relational of of relational of) ( (ov relational relational relational relational relational) relational) relationalial relational relational problem relational for aialial ( ( () relational relational relational relational relational problem relational relational relational relational problem) relational relational relational relational relational relational relational relational) relational relational relational relational relational relational relational relational problem relational problem relational relational relational relational relational relational problem relational relational relational relational relational ( relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational) relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational problem ( () ( ( relational relational relational problem relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational relational) (\n",
            "\n",
            "  Average training loss: 5.96\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.97\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.98\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 5.99\n",
            "  Batch 4,500  of  20,001. Loss: 3.129096269607544.\n",
            "0: In this, use, use use we use using we use use use using using\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 5.99\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.00\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.01\n",
            "  Batch 4,600  of  20,001. Loss: 3.1324057579040527.\n",
            "0: This paper describes describes.\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.01\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.02\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.03\n",
            "  Batch 4,700  of  20,001. Loss: 5.796984672546387.\n",
            "0: But and is is model in and in of the the and is in models of the in. is models models the\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.03\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.04\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "  Batch 4,800  of  20,001. Loss: 4.0860700607299805.\n",
            "0: As a a a present propose a model model, a of a, model\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.05\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.06\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.07\n",
            "  Batch 4,900  of  20,001. Loss: 4.330358028411865.\n",
            "0: In addition, we method a method for a method for method method a method method method method. method method method method method method method method method. method.. method method. method method method.. algorithm method method method\n",
            "\n",
            "  Average training loss: 6.07\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.08\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.09\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "  Batch 5,000  of  20,001. Loss: 3.368067979812622.\n",
            "0: The network algorithm of the the network the domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.10\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.11\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "  Batch 5,100  of  20,001. Loss: 5.049412250518799.\n",
            "0: We prove the demonstrate demonstrate.. demonstrate.\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.12\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.13\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "  Batch 5,200  of  20,001. Loss: 3.3260910511016846.\n",
            "0: This show demonstrate proposed of that of proposed approach that proposed of method proposed.\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.14\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.15\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "  Batch 5,300  of  20,001. Loss: 5.455312252044678.\n",
            "0: In this paper,,, we we we present a a a-based-based new a-. approach-based-basedbased- approach model model a.based. basedbased- model onbased model basedbased on-basedbased based based based. on.basedbased a on based model\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.16\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.17\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.18\n",
            "\n",
            "  Average training loss: 6.19\n",
            "  Batch 5,400  of  20,001. Loss: 5.283041477203369.\n",
            "0: To address paper present, we address an address- address- address address address address address address address\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.19\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.20\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "  Batch 5,500  of  20,001. Loss: 5.39279842376709.\n",
            "0: Furthermore, it should of be this this should this this this this\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.21\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.22\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "  Batch 5,600  of  20,001. Loss: 4.478797435760498.\n",
            "0: Furthermore,, the the to to use and are-- to the the that---- the- is of- and features use use use-- of features and use use use- employ- the-- to- the use--- methods use features and use the used the-- employ- used-- are use- use use use use use use to used used use use use features use use- use use use use use and use use use use used-- use use use-- use use use- the use- use and use use used use- and use- use use- use use- the--- use to to of use use-- of features use- use use use use of use use use features use of use use- use- use use use use use use used employ use use use use use use- use use to use use use features use use-- use features- use use use use use use-- features features use-\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.23\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.24\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.25\n",
            "  Batch 5,700  of  20,001. Loss: 3.4961459636688232.\n",
            "0: Using the resulting algorithm the algorithm algorithm the algorithm, the algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.25\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.26\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "  Batch 5,800  of  20,001. Loss: 3.482158899307251.\n",
            "0: Experiments evaluations that show the show the method proposed method method method method method..\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.27\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.28\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 5,900  of  20,001. Loss: 4.101305961608887.\n",
            "0: The proposed method of proposed on of on of a proposed method method proposed proposed proposed proposed.\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.29\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.30\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.31\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.32\n",
            "  Batch 6,000  of  20,001. Loss: 4.0006208419799805.\n",
            "0: Our algorithm algorithm is and a to and algorithm algorithm algorithm.\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.32\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.33\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 6,100  of  20,001. Loss: 4.167971611022949.\n",
            "0: This code of to of of to of the the the the error error.. error\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.34\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.35\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "  Batch 6,200  of  20,001. Loss: 4.083790302276611.\n",
            "0: Finally, in in non- we a in in in- in a non a nonetric in a non- non non non- non in non, nonlinear nonlinear nonlinear nonlinear- nonlinear nonlinearlinear non nonlinear nonlinear nonlinear nonlinearlinearlinear nonlinear nonlinear nonlinear inussian nonlinear nonlinear nonlinearlinearlinearlinearlinearlinear nonlinearlinear problem nonlinear nonlinear nonlinearlinearlinearlinear nonlinearlinear nonlinear nonlinear nonlinearlinear alinear nonlinear nonlinear nonlinear nonlinear nonlinear nonlinear nonlinear- nonlinear nonlinear nonlinear nonlinear problemlinearlinear- nonlinear non non nonlinear nonlinear inlinear inlinear-linear non nonlinearlinear nonlinearlinearlinearlinear alinearlinear nonlinearlinear nonlinear nonlinear nonlinear problemlinear nonlinear nonlinear nonlinearlinearlinear nonlinear nonlinearlinearlinear nonlinearlinear nonlinear nonlinearlinearlinear alinear- nonlinearlinear nonlinearlinear nonlinear problem non\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.36\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.37\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "  Batch 6,300  of  20,001. Loss: 3.267195463180542.\n",
            "0: This paper paper the problem of of of the of in problem....\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.38\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.39\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.40\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.41\n",
            "  Batch 6,400  of  20,001. Loss: 5.147329807281494.\n",
            "0: The growth the growth is used used the used the growth growth growth growth growth growth growth.\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.41\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.42\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 6,500  of  20,001. Loss: 3.632685899734497.\n",
            "0: The novel novel new new new new new new new new new new new new\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.43\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.44\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 6,600  of  20,001. Loss: 3.8712105751037598.\n",
            "0: Recently,, propose new we new new new new new new new new. new\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.45\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.46\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "  Batch 6,700  of  20,001. Loss: 4.859959125518799.\n",
            "0: It\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.47\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.48\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.49\n",
            "  Batch 6,800  of  20,001. Loss: 4.26223087310791.\n",
            "0: The application the- the-- is-- of the of is is the- the is is application application application application application-- the- is the application application application application application application- application application application\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.49\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.50\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.51\n",
            "\n",
            "  Average training loss: 6.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "  Batch 6,900  of  20,001. Loss: 4.424882411956787.\n",
            "0: Here the the show that that the that demonstrate that that the of results the\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.52\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.53\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "  Batch 7,000  of  20,001. Loss: 3.3676137924194336.\n",
            "0: It\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.54\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.55\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "  Batch 7,100  of  20,001. Loss: 3.887730360031128.\n",
            "0: P, to, P we two, of of to G ofPPPPPP thePPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.56\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.57\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "  Batch 7,200  of  20,001. Loss: 4.095066070556641.\n",
            "0: These features of features the features by by feature by features features features features features features features.\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.58\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.59\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "  Batch 7,300  of  20,001. Loss: 4.558282375335693.\n",
            "0: We provide an present of of provide an provide of of of of of of of anation of an of... of\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.60\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.61\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "  Batch 7,400  of  20,001. Loss: 3.9923202991485596.\n",
            "0: The models the is models models for is is for models models models models models models models models models models models models models models models models models models of modeling modeling models models models models models models models models models models models models models models models models models for models models models models models models models models models models models models models. models models models models models models models modeling models models models models models models models models models models models models for modeling modeling models models models models models models models models models models models models models modeling models for models models modeling models models models models models model models models models models models models models models models for models models models model models model models models models models models models for models modeling models modeling models of models modeling models modeling modeling modeling models models models models models models models for models models models models models for models of models for models models models models modeling models models models models models models models models modeling models models for model models models models models models models models modeling the models models models models models models models models\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.62\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.63\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.64\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "  Batch 7,500  of  20,001. Loss: 5.547088623046875.\n",
            "0: In recent works proposed novel we two-- two\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.65\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.66\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.67\n",
            "  Batch 7,600  of  20,001. Loss: 3.2874257564544678.\n",
            "0: To our demonstrate the our demonstrate results demonstrate the the of our the of method\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.67\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.68\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.69\n",
            "  Batch 7,700  of  20,001. Loss: 3.5167500972747803.\n",
            "0: We address paper two this the this. address\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.69\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.70\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.71\n",
            "  Batch 7,800  of  20,001. Loss: 4.939947605133057.\n",
            "0: This technique a introduces for methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology methodology\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.71\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.72\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.73\n",
            "  Batch 7,900  of  20,001. Loss: 5.004115104675293.\n",
            "0: Our model consists consists two two. two two. two-\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.73\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.74\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.75\n",
            "\n",
            "  Average training loss: 6.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "  Batch 8,000  of  20,001. Loss: 4.2519850730896.\n",
            "0: However, there is here here here here here here here here here here here here here here\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.76\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.77\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "  Batch 8,100  of  20,001. Loss: 4.532898902893066.\n",
            "0: The proposed of the proposed of proposed the proposed the proposed proposed. proposed proposed. proposed.\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.78\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.79\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "  Batch 8,200  of  20,001. Loss: 5.077879428863525.\n",
            "0: Con Conv paper, we a-olution for--Net Networks (al-alsal)alsalalNetsss thes) thealal Networks-sNet neural for NetworksCNN for for--alsal) (Netsal Networks have--)-) Networksssss-sal-uals forualss ( Networks Networkss Networks-edsalCNNsals neural forss neuralolutional networks of for neural neural for Networksss for have the neural networks)al Networks Networksssal ( neurals the for Networksss) Networkss thess)s neurals neuralCNN neural networksssss Networksalalss foral the networks of)ss Networks (ssal have)al thealal networks networks for Networks the the of networksual-sCNNCNN networkss Networksval neural have for thessal networks neuralsCNNs fors\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.80\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.81\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.82\n",
            "  Batch 8,300  of  20,001. Loss: 4.310544490814209.\n",
            "0: We have methods existing methods on state- method methodsart- methods methods methods methods methods methods methods methods methods methods methods methods methods methods methods methods\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.82\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.83\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "  Batch 8,400  of  20,001. Loss: 4.819669246673584.\n",
            "0: We propose a novel a a approach- approach new approach-- two approach approach approach approach approach\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.84\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.85\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.86\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.87\n",
            "  Batch 8,500  of  20,001. Loss: 4.93844747543335.\n",
            "0: However, the is and an not there is no no no no no no no no no\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.87\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.88\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "  Batch 8,600  of  20,001. Loss: 4.744327545166016.\n",
            "0: In this, we, formulate analyze investigate analyze analyze, analyze, analyze analyze analyze. analyze\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.89\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.90\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.91\n",
            "  Batch 8,700  of  20,001. Loss: 4.786668300628662.\n",
            "0: Using the results results the algorithm and show that demonstrate algorithm algorithm results algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.91\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.92\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "  Batch 8,800  of  20,001. Loss: 3.2690553665161133.\n",
            "0: An this work is this this novel.\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.93\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.94\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "  Batch 8,900  of  20,001. Loss: 3.9129562377929688.\n",
            "0: The performance performance show that show that that that performance performance that on performance performance performance performance performance. performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.95\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.96\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.97\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "  Batch 9,000  of  20,001. Loss: 3.591830253601074.\n",
            "0: Second, other can other other other other, other the other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.98\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 6.99\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.00\n",
            "  Batch 9,100  of  20,001. Loss: 4.853407382965088.\n",
            "0: Most approaches, approaches propose methods,,,, which approaches, the approaches, approaches approaches approaches,, approaches and approaches approaches approaches approaches approaches approaches approaches. approaches approaches approaches approaches approaches approaches approaches\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.00\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.01\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 9,200  of  20,001. Loss: 6.24895715713501.\n",
            "0: A new new new the new new of proposed for for proposed to new of proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed. proposed\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.02\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.03\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "  Batch 9,300  of  20,001. Loss: 3.1426241397857666.\n",
            "0: Second, these these we these these evaluate evaluate several several demonstrate. datasets.\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.04\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.05\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.06\n",
            "  Batch 9,400  of  20,001. Loss: 3.462230920791626.\n",
            "0: We also the method the method our method method method method method method..\n",
            "\n",
            "  Average training loss: 7.06\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.07\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.08\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "  Batch 9,500  of  20,001. Loss: 6.146422386169434.\n",
            "0: We propose paper an algorithm for new algorithm. algorithm new algorithm for algorithm algorithm\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.09\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.10\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 9,600  of  20,001. Loss: 4.907492160797119.\n",
            "0: This paper a novel a a deep a deep deep deep deep neuralalolutionalalalalalolutional deep deep deep deep deep deep architectureolutional deep deep deep deep networks deep deep networksal deep neural deep deep deep deep deep deep deep architecturesalolutional neural neuralalal deep foral deepal neuralolutional networks deep neural deep deep neural deep deep deep deep deep deep deep novel deep deep architectures learning deep deep deep learning deepal learning deep deep deep deep deep deep learning deep deep deep deep learning deep deep deep deep deep deep deep learning deep deep deep deepolution for deep deep deep deep deep deep deep deep conv deep neural deep deep neural deep deep neural network learning deep deep deep neural deep deep deep deep deep deep for deep deep deep deep deep deep learning networks deep deep deep deep deep deep deep learning deep deep deep deep deep deep deep deep deep learning deep deep deep deep deep deep deep learning deep deep deep deep deep deepolution networks neural deep deep deep deep deep neural architectures deep learning deep\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.11\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.12\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 9,700  of  20,001. Loss: 3.836244583129883.\n",
            "0: The model by model consists through through model through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through through\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.13\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.14\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "  Batch 9,800  of  20,001. Loss: 5.765721797943115.\n",
            "0: This is, the on we two-- to proposed, two proposed the proposed proposed the,,-- the- proposed on and,,-, proposed proposed proposed proposed proposed two the- both proposed proposed proposed on two proposed the proposed-NetNet proposed proposedNet proposed\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.15\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.16\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.17\n",
            "  Batch 9,900  of  20,001. Loss: 3.2783188819885254.\n",
            "0: We propose to novel a propose to approach to propose propose to approach approach approach..\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.17\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.18\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.19\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.20\n",
            "  Batch 10,000  of  20,001. Loss: 4.747912883758545.\n",
            "0: These are are these used these these used these used used\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.20\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.21\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.22\n",
            "  Batch 10,100  of  20,001. Loss: 5.495517730712891.\n",
            "0: Our data requires is data requiring requiring requiring\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.22\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.23\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "  Batch 10,200  of  20,001. Loss: 3.8661162853240967.\n",
            "0: We provide a a a a the method proposed a of a of a method method\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.24\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.25\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.26\n",
            "  Batch 10,300  of  20,001. Loss: 5.279633522033691.\n",
            "0: The results experiments the the are on demonstrate simulations experiments simulations simulations.\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.26\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.27\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.28\n",
            "  Batch 10,400  of  20,001. Loss: 4.997901916503906.\n",
            "0: Furthermore, we propose propose a new novel approach for approach for- a deep deep for for.. a deep deep for deep- deep new deep. for a deep deep novel. learning for new approach a deep deep deep for new- deep learning learning learning. deep for deep learning deep- new deep for deep deep learning- approach deep for new deep deep for deep deep for learning learning learning for new for learning learning a for deep deep deep a deep approach deep deep deep deep for a for new deep new deep new training deep deep deep- a of novel deep deep training deep-learning a deep learning deep learning a a new deep deep we deep deep new deep learning approach approach deep deep deep for new deep deep deep deep deep new new new new a new new new new deep framework a deep new new deep deep deep method training network network network new new deep learning deep deep deep deep learning deep deep learning approach deep deep learning a a method deep deep deep deep deep framework avised learning learning learning for\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.28\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.29\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.30\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.31\n",
            "  Batch 10,500  of  20,001. Loss: 3.3648602962493896.\n",
            "0: Two differentolution different differentCNNCNNCNNCNN differentCNNCNNal theal)olutionCNNCNNCNN differentCNNolutionCNN neuralCNNCNNCNNCNNCNNal differentolution conv convolutionCNNCNN differentalCNNalalolutionCNNolutionCNNolutionalCNNolutionolutionalolution neuralolution convCNNCNNCNNCNN the convolutionCNNsCNN differentolutionalolutionCNNal different convalalCNNolutionCNNsCNNCNNCNN neuralCNNCNNCNNal neuralCNNolutionCNNCNNCNNCNNalalCNNCNNCNNsalolution layers neuralalolutionCNNCNNCNNCNNCNNolutionalalCNNolutionCNNalolutionalal convalolutionalolutionalCNNCNNolutionCNNolution convCNNCNNalolutionalCNNolutionCNN differentolution differentalCNNCNN neuralolutional convolutionalalCNNCNNCNNals convCNN differentalCNNCNNalCNNCNNolutionCNN convalCNNCNNCNNCNN convolutionCNNCNN differentolutionalCNN convalolutionolution neuralCNNolutional neuralal convolution networks\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.31\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.32\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 10,600  of  20,001. Loss: 3.001570701599121.\n",
            "0: We show show that that that show show that the show show show results on datasets\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.33\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.34\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.35\n",
            "  Batch 10,700  of  20,001. Loss: 5.433218479156494.\n",
            "0: We show evaluations show we that show that that our state state state state statetheofart- state statethe state stateofof state--of that-of-of- stateofart-artthe-of state stateofformsart-artartofart- state-art- state-theofofof-theofthe- state-ofof-ofofart our---the-ofofart-artart---of-ofartartthe our ourof-artthe stateofof-- our- state-artof-artartartofartartof--ofartart- ourtheof state-thetheofof-theart------of statearttheartartart----thethe statethe--artthethearttheartartart-artart--art stateartof-art---art---theart-the-of-of\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.35\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.36\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "  Batch 10,800  of  20,001. Loss: 5.898779392242432.\n",
            "0: This paper a two a sparse novel novel two sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse sparse\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.37\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.38\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.39\n",
            "  Batch 10,900  of  20,001. Loss: 3.875772476196289.\n",
            "0: The system system been has has been system been in an in has in.\n",
            "\n",
            "  Average training loss: 7.39\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.40\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.41\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "  Batch 11,000  of  20,001. Loss: 3.6335999965667725.\n",
            "0: In the,,,,, the, paper-,- propose, the method to proposed method- method proposed method- method to method proposed method proposed of method method- method the method of proposed method method,, method proposed method method method method to method method- method method method method method the proposed of method method method proposed method method method proposed method of method proposed the method method method method method method of method method method method method method the proposed proposed method the proposed of is proposed method proposed proposed method method proposed proposed proposed proposed, method method method method method method method method method method method of method method method method approach method method method method method of method the method proposed method method method method proposed of method method method method method method proposed method proposed the method method method method proposed the method to method method method method method method the method method method- method method method proposed method method method method method method method proposed proposed method the method method method method method method the method method method of method of method method\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.42\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.43\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.44\n",
            "  Batch 11,100  of  20,001. Loss: 5.823146820068359.\n",
            "0: We analyze, statistical statistical statistical analytical analytical analyze analyze analytical and analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical analytical\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.44\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.45\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "  Batch 11,200  of  20,001. Loss: 4.221273899078369.\n",
            "0: Furthermore, we we paper novel propose we the for a framework novel the framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework framework\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.46\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.47\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "  Batch 11,300  of  20,001. Loss: 4.389444828033447.\n",
            "0: In this paper, we introduce a novel novel multi novel multi- multi multi cross cross- cross cross cross- cross- cross cross- cross cross cross- cross cross cross cross cross cross cross cross cross cross- cross crossvised cross cross cross cross cross cross cross cross cross- cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross cross\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.48\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.49\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.50\n",
            "\n",
            "  Average training loss: 7.51\n",
            "  Batch 11,400  of  20,001. Loss: 4.306568622589111.\n",
            "0: Our method achieves achieves is proposed is achieves achieves., shows.\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.51\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.52\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 11,500  of  20,001. Loss: 2.521472215652466.\n",
            "0: It is the is there the there there, there is, there there there is is there is there there. there there\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.53\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.54\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "  Batch 11,600  of  20,001. Loss: 5.065973281860352.\n",
            "0: Our experimental results is conducted of conducted of conducted conducted conducted is.\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.55\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.56\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 11,700  of  20,001. Loss: 4.038808822631836.\n",
            "0: To our, work work the we propose- previous a previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous previous\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.57\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.58\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "  Batch 11,800  of  20,001. Loss: 3.2805471420288086.\n",
            "0: Recently work paper,, been has proposed has the have proposed the proposed proposed.. proposed..\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.59\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.60\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.61\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "  Batch 11,900  of  20,001. Loss: 3.945071220397949.\n",
            "0: A algorithm algorithm a, a using is algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm algorithm\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.62\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.63\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "  Batch 12,000  of  20,001. Loss: 3.510070323944092.\n",
            "0: The automated the on performance the on the on a the based the the on on.\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.64\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.65\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "  Batch 12,100  of  20,001. Loss: 3.6269285678863525.\n",
            "0: We demonstrate our demonstrate of on of several state----- the.\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.66\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.67\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "  Batch 12,200  of  20,001. Loss: 5.223607063293457.\n",
            "0: Deep networks theolutionolutionolution deep neural neural deepCNN deep) forolutionCNNolutionCNN neuralal Networksolutionolution convolutionolutionCNNConCNN network network architectureal neural neural conv) deepolutionolution neural for a the (- network neuralCNN) neural for for for conv neuralCNN a conv conv network neural neural) neural forCNNal neural neural- neural network convCNNolution conv neural conv deepolutionolution ofal the the network) conv conv convalCNN-)al the network for architecture deep neural neuralolution network neural image)olution conv image neural network- network ofolution neural the networkNet network architecture for image) conv- network conv neural conv convolution convolution neural neural network forolution (s for network neuralalolutionolution image super) network neural network) aolutionCNN of for deep for have conv deepCNN supers) ( neural image super neural (CNNolution image) for network of the network) neural deep a of super of for image to image image forresolution\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.68\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.69\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "  Batch 12,300  of  20,001. Loss: 4.791622161865234.\n",
            "0: It work work the the the first the future future future work work work work work work work work work work work work work work work work work work work work work work work work work work work work work work work work.\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.70\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.71\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.72\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "  Batch 12,400  of  20,001. Loss: 3.456120252609253.\n",
            "0: This work work the the the problem\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.73\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.74\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "  Batch 12,500  of  20,001. Loss: 4.105313301086426.\n",
            "0: However, data both results effectiveness to demonstrate both datasets our and and effectiveness.\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.75\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.76\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "  Batch 12,600  of  20,001. Loss: 4.597721099853516.\n",
            "0: The new results results of new of obtained obtained of new new obtained.\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.77\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.78\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "  Batch 12,700  of  20,001. Loss: 4.536596298217773.\n",
            "0: Convolution Conv Neural Networks Conval neuralvalal neural have Convvs, Neuralolutional neuralCNN have have Networkss have ( (sCNNs have ( Conv haves- have (CNNss have,alolution Networkssal) Networks)) haves the theCNNalolutionv have have for Conv- have neuralCNNs- thesal neural neural haveval have have have neural forssCNN have neuralsalv NeuralCNNs have beenss have thes haveal fors neurals a haveals the have havessss haveCNNs neurals vision theolutionvCNN have ( have have thevsCNNolutions neural neuralss Networkss (val networkssolutionvolutions haveCNN deep as neurals have, the ( fors haves, the have have have havevs have-s haveCNN have networks have have have haveCNNs) have have have have been)\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.79\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.80\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.81\n",
            "  Batch 12,800  of  20,001. Loss: 4.74054479598999.\n",
            "0: Our method method is state proposed statethethe method- state- state to method statethe statethethe- state-the--the to state---of- proposedartthe-theofthe--ofof state-the statethe method method onthe state-of statethethe- state-theof proposedtheof statetheofthethe---the state-art-the--theof state theof-the- statethe-the-of methodthetheof-- statethe thetheart-theofartthe state stateart statetheofartthe thearttheof--of------ state method statetheart-artthe state- methodtheof tothe statethe statethe state methodthe--thethe-art-artthe to state-art- methodofthetheof-thetheart--theartthe-art- statetheofthe-thethethe statethe\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.81\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.82\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.83\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "  Batch 12,900  of  20,001. Loss: 4.635362148284912.\n",
            "0: However the other the to to is other is to, in due due.\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.84\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.85\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.86\n",
            "  Batch 13,000  of  20,001. Loss: 5.2924017906188965.\n",
            "0: So using cases method, of method method method demonstrate method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.86\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.87\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.88\n",
            "  Batch 13,100  of  20,001. Loss: 4.6051530838012695.\n",
            "0: These concepts can examples be to be explained explained explained explained explained explained explained explained explained explained.\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.88\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.89\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.90\n",
            "  Batch 13,200  of  20,001. Loss: 4.110160827636719.\n",
            "0: A method a multi novel novel method multi a novel mult mult a mult novel mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult mult\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.90\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.91\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 13,300  of  20,001. Loss: 6.322239398956299.\n",
            "0: The proposed achieves that achieves proposed proposed achieves state the-art state- achieves that-artart thatofartart methods stateof state-of-theartart statethe---of---art--of-of-ofofthe-theart- state-theartartartof-art-artartartartart statethethe--oftheof-ofofthetheof stateofartart statethe- state-art- state-art-ofof- thetheartofartthe-theof-of-of-art--ofthe-theartof---artof state statethe-of-art--of performanceartart-the-art-art--ofofofart- state-art-theofofartartof-theartartartthe state- theart--the- statethe-art stateof-of-- statetheartthe--thethe\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.92\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.93\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.94\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "  Batch 13,400  of  20,001. Loss: 4.934957027435303.\n",
            "0: It is is a approach the a approach for of of approach approach approach\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.95\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.96\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.97\n",
            "  Batch 13,500  of  20,001. Loss: 3.880751848220825.\n",
            "0: To the the, the, the, proposed can proposed to proposed proposed to be proposed.\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.97\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.98\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 7.99\n",
            "  Batch 13,600  of  20,001. Loss: 4.009069919586182.\n",
            "0: However, a a- be can used- and- be used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 7.99\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.00\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "  Batch 13,700  of  20,001. Loss: 4.74038553237915.\n",
            "0: This also also the with also the complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity complexity\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.01\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.02\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.03\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 13,800  of  20,001. Loss: 2.9496583938598633.\n",
            "0: Finally, the further further further further further is further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further further\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.04\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.05\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "  Batch 13,900  of  20,001. Loss: 3.3872644901275635.\n",
            "0: The proposed the approach the the of our proposed. and effectiveness\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.06\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.07\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.08\n",
            "  Batch 14,000  of  20,001. Loss: 3.3939321041107178.\n",
            "0: The system consists system consists consists includes includes consists main consists.\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.08\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.09\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.10\n",
            "  Batch 14,100  of  20,001. Loss: 3.4226315021514893.\n",
            "0: This approach also is is is approach approach approach approach is approach approach approach approach.\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.10\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.11\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 14,200  of  20,001. Loss: 5.152195930480957.\n",
            "0: In this paper, an an study an of analysis analysis an analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis analysis.\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.12\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.13\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.14\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.15\n",
            "  Batch 14,300  of  20,001. Loss: 4.841177463531494.\n",
            "0: Finally, we the and two the of this demonstrate the of the model of proposed proposed proposed. proposed the proposed. proposed proposed proposed. proposed model model model is proposed\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.15\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.16\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "  Batch 14,400  of  20,001. Loss: 5.412109375.\n",
            "0: In this,,, we,, we we the we we demonstrate demonstrate.\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.17\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.18\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "  Batch 14,500  of  20,001. Loss: 5.008444309234619.\n",
            "0: We train a- trainto- train, learn- train train train train train train train train train train train, train train a train train train train train train train train- train train train train train train train- train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train- train train train train train train train train train train- train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train- train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.19\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.20\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "  Batch 14,600  of  20,001. Loss: 4.407839775085449.\n",
            "0: This paper requires requires this requires requiresization requires requires requires requires requires requires requires requires requires requires\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.21\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.22\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.23\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "  Batch 14,700  of  20,001. Loss: 3.3251476287841797.\n",
            "0: Finally, we present present two to to two to approach approaches approaches to approach. approach.\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.24\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.25\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "  Batch 14,800  of  20,001. Loss: 4.383516788482666.\n",
            "0: The paper is an is is an an of an of is of an is\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.26\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.27\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "  Batch 14,900  of  20,001. Loss: 4.533356666564941.\n",
            "0: We use a a a propose a new new using using using.. class class classifier.\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.28\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.29\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.30\n",
            "  Batch 15,000  of  20,001. Loss: 6.079614162445068.\n",
            "0: Our results that evaluations that that this, show demonstrate that the we- outper outper-- outper outper methods methods-forms methods outper state---the, outperformart-the state outper-,-the---the- previous the methods previous previous-- outper-forms thatformsforms- theforms-- outper outperforms-- outper statethethe previous previous methodsthe previous previousthe that the- outper previous- previous methodstheart methodsthe----- previousform methods- the the thethe previous previous that previous-theof- state state state state-formsart- the-- the state the previous methods- outper the- state outperthe the- previous previous previous previous----- outper previous previous-- previous previous previous-art-formsthe algorithms-ofthe previous previous- the previous---the statethe- previous previous previous previous previous previous previous- previous previous the state- previous previous previous previoustheforms the the\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.30\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.31\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "  Batch 15,100  of  20,001. Loss: 3.6061229705810547.\n",
            "0: However, large expensive. for large data large large large large large expensive.\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.32\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.33\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "  Batch 15,200  of  20,001. Loss: 2.9205586910247803.\n",
            "0: For this,, we we, a propose we approach and.\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.34\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.35\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.36\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "  Batch 15,300  of  20,001. Loss: 6.152143955230713.\n",
            "0: We have some have, some of, some have not not, not some, these not, not results some have some some have some some some have many some some some, some some some some some some some some some some some some, not some some some, some some some some some some some some some some, some have some some some some some some some some some some of some, not some have some some some some some some some have some some some some some some some some some several some some several some not some some results some there some some some some some have some some some some some some, some some some some some some, some some some some some some some some some some some some some some have some some some some,, some some have some some some some have some, some some some some some some have some have some some some some some some some some have some some have some some some some some some, some some some some have some some have some some\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.37\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.38\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "  Batch 15,400  of  20,001. Loss: 2.8345582485198975.\n",
            "0: The network in the of in of is an of network network- of of- network network-- in network a network- network network network networknetwork networks network networks network in in in architecture in network network is in in in of network the the networks network network network- neuralal the network the in network in in network.\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.39\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.40\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 15,500  of  20,001. Loss: 4.476757526397705.\n",
            "0: We show that show show that show that results show that show show show results results\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.41\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.42\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.43\n",
            "  Batch 15,600  of  20,001. Loss: 5.61886739730835.\n",
            "0: We show a a that show that that very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.43\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.44\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "  Batch 15,700  of  20,001. Loss: 4.505447864532471.\n",
            "0: Here the consider the of of the of of of of the the of these.\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.45\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.46\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.47\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "  Batch 15,800  of  20,001. Loss: 5.894321918487549.\n",
            "0: Here, we we consider an as as an the as as as as as as as as an problem as as is the as as as as as as as as as as as as as as as as of problem an as the as an of as as problem of of as problem problem problem problem as the as\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.48\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.49\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.50\n",
            "  Batch 15,900  of  20,001. Loss: 3.4732542037963867.\n",
            "0: Extensive experiments the effectiveness proposed our demonstrate- our effectiveness our effectiveness effectiveness effectiveness effectiveness effectiveness effectiveness effectiveness approach approach approach effectiveness approach proposed proposed proposed proposed approach effectiveness approach approach approach approach approach.\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.50\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.51\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.52\n",
            "  Batch 16,000  of  20,001. Loss: 2.609126567840576.\n",
            "0: This algorithm is is a problem..- a. problem\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.52\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.53\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "  Batch 16,100  of  20,001. Loss: 3.3401668071746826.\n",
            "0: The model consists model model model model includes consists model model model model model model model model model model model. model model model model model\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.54\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.55\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.56\n",
            "  Batch 16,200  of  20,001. Loss: 4.444835662841797.\n",
            "0: We evaluate two evaluate of two two two. evaluate\n",
            "\n",
            "  Average training loss: 8.56\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.57\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.58\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "  Batch 16,300  of  20,001. Loss: 4.155857086181641.\n",
            "0: We apply describe this describe the describe describe to describe the.\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.59\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.60\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.61\n",
            "  Batch 16,400  of  20,001. Loss: 4.831066131591797.\n",
            "0: The second on presents on on on based our based based the on- basedbased based based on-- based based on on- based based based based based based of on of based based on based.- based\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.61\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.62\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.63\n",
            "  Batch 16,500  of  20,001. Loss: 4.385585784912109.\n",
            "0: The proposed network proposed network is network proposed proposed proposed.. proposed proposed\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.63\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.64\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.65\n",
            "  Batch 16,600  of  20,001. Loss: 4.452971935272217.\n",
            "0: Our approach offers gives gives to for offers gives gives gives gives gives gives gives\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.65\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.66\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.67\n",
            "\n",
            "  Average training loss: 8.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.68\n",
            "  Batch 16,700  of  20,001. Loss: 4.689504623413086.\n",
            "0: We also show also compare that the our method method method method method. method method\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.68\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.69\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "  Batch 16,800  of  20,001. Loss: 3.3905491828918457.\n",
            "0: These techniques techniques methods techniques are tasks for techniques tasks for tasks tasks tasks tasks tasks tasks.\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.70\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.71\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "  Batch 16,900  of  20,001. Loss: 3.901303768157959.\n",
            "0: Experimental results indicate results the demonstrate show our the proposed show proposed.. proposed\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.72\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.73\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "  Batch 17,000  of  20,001. Loss: 5.281388759613037.\n",
            "0: Finally, a a a a the a a a is a a of of that the of. of. a of\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.74\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.75\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.76\n",
            "  Batch 17,100  of  20,001. Loss: 3.6408369541168213.\n",
            "0: Experimental results suggest show results experimental suggest provide experimental experimental experimental suggest, experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental. experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental experimental\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.76\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.77\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n",
            "\n",
            "  Average training loss: 8.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "  Batch 17,200  of  20,001. Loss: 6.294752597808838.\n",
            "0: We present a a- approach a-- approach-- a approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach approach\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.79\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.80\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "  Batch 17,300  of  20,001. Loss: 6.516264915466309.\n",
            "0: In this work, we the of a of address the of of of of of of of\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.81\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.82\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "  Batch 17,400  of  20,001. Loss: 4.002654552459717.\n",
            "0: When an is where there is,- is an an an an an is is is where is an is an is an an this is an there is an an an an an an is is is is is is an. an important.... is an. an\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.83\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.84\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.85\n",
            "  Batch 17,500  of  20,001. Loss: 5.097367763519287.\n",
            "0: We present this, a a a a,, the, two two a, two two two two two the two of two two these...\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.85\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.86\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n",
            "\n",
            "  Average training loss: 8.87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.88\n",
            "  Batch 17,600  of  20,001. Loss: 5.134364604949951.\n",
            "0: This helps helps helps helps helps helps helps helps helps helps helps helps helps helps helps\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.88\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.89\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "  Batch 17,700  of  20,001. Loss: 4.412749290466309.\n",
            "0: It is is the model model to learn the model model to to model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model model\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.90\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.91\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 17,800  of  20,001. Loss: 4.39089822769165.\n",
            "0: This code contains and contains and contains contains, code, codes our codes and and codes codes. codes codes codes codes. codes..\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.92\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.93\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "  Batch 17,900  of  20,001. Loss: 5.896488666534424.\n",
            "0: Thus, a model model is model model is model model model model model a\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.94\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.95\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.96\n",
            "  Batch 18,000  of  20,001. Loss: 4.440145969390869.\n",
            "0: Such work can be be be be work work work. paper in in work work work work work work work work work work work work work work work work work\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.96\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.97\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.98\n",
            "\n",
            "  Average training loss: 8.99\n",
            "  Batch 18,100  of  20,001. Loss: 4.510743141174316.\n",
            "0: We also suggest a general problemizationization a generalizationizationizationizationizationizationizationizationizationizationization generalizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationizationization\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 8.99\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.00\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.01\n",
            "  Batch 18,200  of  20,001. Loss: 5.078155994415283.\n",
            "0: We propose a propose an for propose based on based a based based based method\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.01\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.02\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.03\n",
            "  Batch 18,300  of  20,001. Loss: 5.3860182762146.\n",
            "0: The network is layer-- layer layer- layer--- layer- layer layer network layer- layer. network network\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.03\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.04\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "  Batch 18,400  of  20,001. Loss: 2.987071990966797.\n",
            "0: This paper presents an in for approach in for in\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.05\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.06\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.07\n",
            "  Batch 18,500  of  20,001. Loss: 3.715593099594116.\n",
            "0: Both that suggest indicate suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest suggest\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.07\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.08\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.09\n",
            "  Batch 18,600  of  20,001. Loss: 4.545607089996338.\n",
            "0: Therefore, a of performance is a performance a a performance,- of performance performance performance performance. performance performance performance performance\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.09\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.10\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.11\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "  Batch 18,700  of  20,001. Loss: 4.452622890472412.\n",
            "0: We consider a a problem problem problem the problem problem problem problem problem problem problem\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.12\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.13\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.14\n",
            "  Batch 18,800  of  20,001. Loss: 3.382183313369751.\n",
            "0: Deep-olution- been neuralalal have networks networks hasal have networks- networks\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.14\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.15\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.16\n",
            "  Batch 18,900  of  20,001. Loss: 4.121049404144287.\n",
            "0: A A proposed shows model proposed is is proposed proposed, is proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed is proposed proposed. is proposed proposed proposed. is\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.16\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.17\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "  Batch 19,000  of  20,001. Loss: 7.586787223815918.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: This makes the is the the the on of the the this on on.\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.18\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.19\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.20\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "  Batch 19,100  of  20,001. Loss: 3.474123954772949.\n",
            "0: We do do- be the, do do- not, do do do do- require to not not may the to,. not.\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.21\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.22\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 19,200  of  20,001. Loss: 4.927722454071045.\n",
            "0: In this,,,,,, we propose we the the framework on and- the of this- the of model and and based- model and- model of model on the model model model model- model and- of-- model based model of of the of on estimation model on and the models models the, model based model model models- model- on of of of estimation models of this models- models. model and model model models of model models models and models the network andbased-- model model of training model the of\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.23\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.24\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "  Batch 19,300  of  20,001. Loss: 5.022339820861816.\n",
            "0: It is a is a as well, as as a not known\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.25\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.26\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 19,400  of  20,001. Loss: 4.477342128753662.\n",
            "0: To this, we propose an propose paper paper an an approach an an to an solve problem to a problem to problem problem problem problem. optimization optimization an optimization an an. an problem problem problem...\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.27\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.28\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.29\n",
            "  Batch 19,500  of  20,001. Loss: 4.566938400268555.\n",
            "0: We consider the the the the problem the- on of of of on of- on-- of the this address-- problem this-- problem problem problem problem- problem- problem of- problem problem problem problem problem- problem problem problem the the problem problem- problem problem.- problem\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.29\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.30\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.31\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.32\n",
            "  Batch 19,600  of  20,001. Loss: 4.968236923217773.\n",
            "0: A resulting of a a the a of a of is a a the a\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.32\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.33\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "  Batch 19,700  of  20,001. Loss: 6.69556999206543.\n",
            "0: The of is problem representation the important the problem representation representation of representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representations representations representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representations representation representations representations representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representations representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representations representations representations representations representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representations representation representation representation representation representation representation representations representation representation representation representation representation representation representation representation representation representation representations representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representation representations representations representation representation representation representation representation representation representation representation representations representation representation representation representation representations representation representation representation\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.34\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.35\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "  Batch 19,800  of  20,001. Loss: 2.715684652328491.\n",
            "0: Such examples are that show examples that example are examples examples examples. example examples examples examples examples\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.36\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.37\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.38\n",
            "  Batch 19,900  of  20,001. Loss: 3.525160551071167.\n",
            "0: The experiments that effectiveness show effectiveness that demonstrate effectiveness effectiveness on proposed the proposed proposed proposed proposed proposed\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.38\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.39\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "  Batch 20,000  of  20,001. Loss: 5.223104000091553.\n",
            "0: In particular, we we we a to a to we- method. a.\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.40\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.41\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "  Batch   100  of  20,001. Loss: 3.992394208908081.\n",
            "0: We also also different of different different different different different different different different different types.\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.42\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.43\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "  Batch   200  of  20,001. Loss: 3.561591386795044.\n",
            "0: We empiricallyically empiricallyicallyically empiricallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyically empiricallyicallyically empiricallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyicallyically\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.44\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.45\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.46\n",
            "  Batch   300  of  20,001. Loss: 3.913313627243042.\n",
            "0: We find present to that find that find find that find find present present\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.46\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.47\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.48\n",
            "  Batch   400  of  20,001. Loss: 4.494276523590088.\n",
            "0: This work describes novel novel novel novel novel novel novel novel novel novel novel novel novel novel novel...\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.48\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.49\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   500  of  20,001. Loss: 2.478696823120117.\n",
            "0: First, we are two types two two the two to types two the types types.\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.50\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.51\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.52\n",
            "  Batch   600  of  20,001. Loss: 3.472524881362915.\n",
            "0: In addition, it been H H H H been Hap Haphh HapapIR HapIR H HIR HIR H have H been HIR H H H been H HIRIR HIR HIR H H HH H H HapIR HHH H been H HIRIR H H HIR H Hap H H H HhH H HH H been HIR H HIR H HIR H H HIRH H been HIR HH H have H H H HIRH H HIR H H HH H H HH H HH H H H H H HH HIR H H H H HHh H H H HIR HH HHapIRh H H H HH H H H H H H H HIR H H H H H H HH H H H H HIR H H H H HIR H HIR H H H H H H HIR H HIR\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.52\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.53\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.54\n",
            "  Batch   700  of  20,001. Loss: 4.658502101898193.\n",
            "0: This makes an easy\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.54\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.55\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "  Batch   800  of  20,001. Loss: 3.173910140991211.\n",
            "0: A original consists method the includes original includes three original. original original original original\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.56\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n",
            "\n",
            "  Average training loss: 9.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "  Batch   900  of  20,001. Loss: 3.4076759815216064.\n",
            "0: We demonstrate that the this that the that that that of. in of\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.58\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n",
            "\n",
            "  Average training loss: 9.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.60\n",
            "  Batch 1,000  of  20,001. Loss: 4.430963039398193.\n",
            "0: However, the process tedious tedious, tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious tedious\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.60\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "  Batch 1,100  of  20,001. Loss: 2.908895492553711.\n",
            "0: In this work, we we an an the address on on on on work\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.61\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.62\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.63\n",
            "  Batch 1,200  of  20,001. Loss: 3.3120932579040527.\n",
            "0: In recent work, we discuss comprehensive of of review recent progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress progress\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.63\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.64\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "  Batch 1,300  of  20,001. Loss: 2.825249671936035.\n",
            "0: The proposed proposed of results of of the the proposed proposed of of proposed proposed proposed\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.65\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.66\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,400  of  20,001. Loss: 4.029024600982666.\n",
            "0: We introduce introduce introduce- new new new- new new new- new new new new\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.67\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.68\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "  Batch 1,500  of  20,001. Loss: 3.24133038520813.\n",
            "0: In this work,, we an an to- an-basedbased to---basedbased approachbasedbasedbased approachbasedbased-basedbased-basedbasedbasedbasedbasedbasedbasedbasedbasedbased-basedbasedbasedbased approachbased- approachbasedbasedbasedbasedbased-basedbasedbasedbasedbasedbased approachbased-basedbased-basedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbased approachbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbased-basedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbased-basedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbasedbased\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.69\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.70\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "  Batch 1,600  of  20,001. Loss: 3.3506240844726562.\n",
            "0: This leads end an solution an solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution solution\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.71\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.72\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.73\n",
            "  Batch 1,700  of  20,001. Loss: 3.815091133117676.\n",
            "0: Theoretical approach to to approach theoretical empirical approach validate approach approach approach\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.73\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.74\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.75\n",
            "  Batch 1,800  of  20,001. Loss: 3.8498733043670654.\n",
            "0: The proposed method method is proposed proposed proposed proposed proposed proposed proposed proposed proposed proposed\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.75\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.76\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "  Batch 1,900  of  20,001. Loss: 2.9207091331481934.\n",
            "0: We suggest suggest suggest this this suggested\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.77\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.78\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.79\n",
            "  Batch 2,000  of  20,001. Loss: 4.9764628410339355.\n",
            "0: Our framework is in framework used and with used with used framework framework framework framework framework framework framework framework framework framework framework. framework framework framework framework. framework framework framework\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.79\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.80\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "  Batch 2,100  of  20,001. Loss: 3.1605417728424072.\n",
            "0: Our results that that the that method the the the method accuracy the performance the..\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.81\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.82\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "  Batch 2,200  of  20,001. Loss: 4.533768177032471.\n",
            "0: However, a of problem is in a in of difficult problem.\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.83\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "  Batch 2,300  of  20,001. Loss: 4.016958713531494.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: We study the of on the the of on of the this on.\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.84\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.85\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "  Batch 2,400  of  20,001. Loss: 3.36740779876709.\n",
            "0: The resulting an of model the of the of of of resulting resulting resulting resulting resulting resulting\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.86\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.87\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "  Batch 2,500  of  20,001. Loss: 3.7949249744415283.\n",
            "0: This is evaluated evaluated evaluated evaluated evaluated evaluated on evaluated is evaluated\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.88\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.89\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.90\n",
            "  Batch 2,600  of  20,001. Loss: 3.8623833656311035.\n",
            "0: The algorithm of the a is set of is of of of set set set set set.\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.90\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.91\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.92\n",
            "  Batch 2,700  of  20,001. Loss: 4.343108177185059.\n",
            "0: We propose, we we, new new new new new new new. novel. new\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.92\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.93\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.94\n",
            "  Batch 2,800  of  20,001. Loss: 2.8492820262908936.\n",
            "0: However, digital the digital of to digital digital digital digital to digital digital digital digital digital\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.94\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.95\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.96\n",
            "  Batch 2,900  of  20,001. Loss: 3.638192892074585.\n",
            "0: This scheme employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs employs\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.96\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.97\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Average training loss: 9.98\n",
            "  Batch 3,000  of  20,001. Loss: 3.747349500656128.\n",
            "0: The resulting model of features model resulting model consists model resulting model model model model.\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.98\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 9.99\n",
            "\n",
            "  Average training loss: 10.00\n",
            "\n",
            "  Average training loss: 10.00\n",
            "\n",
            "  Average training loss: 10.00\n",
            "\n",
            "  Average training loss: 10.00\n",
            "\n",
            "  Average training loss: 10.00\n",
            "\n",
            "  Average training loss: 10.00\n",
            "\n",
            "  Average training loss: 10.00\n",
            "\n",
            "  Average training loss: 10.00\n",
            "\n",
            "  Average training loss: 10.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#monitoring GPU memory consumption \n",
        "from pynvml import *\n",
        "\n",
        "def print_gpu_utilization():\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
        "print_gpu_utilization())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "7QxllPWwI1ki",
        "outputId": "689a03da-b233-4dbe-a057-ede5dcc5d146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-991280512b09>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    print_gpu_utilization())\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yPYlC8o9Pm5n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}